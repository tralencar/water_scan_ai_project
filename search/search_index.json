{"config":{"lang":["pt"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Water Scan AI","text":"<p>\ud83d\udca7 Water Scan AI is a Machine Learning project that classifies water potability using preprocessing techniques, class balancing, hyperparameter optimization, and model versioning with MLflow.</p> <ul> <li>Project Name: <code>water_scan_ai</code></li> <li>Author: <code>tralencar</code></li> <li>Version: \"1.0.1\"</li> <li>License: <code>MIT</code></li> <li>Keywords: <code>quality</code>, <code>water</code></li> <li>Data Source: Dataset (Water Quality) from Kaggle.</li> </ul>"},{"location":"#visual-identity-of-the-water-scan-ai-logo","title":"\ud83d\udd39 Visual Identity of the Water Scan AI logo","text":"<p>The Water Scan AI logo is more than just a visual representation; it encapsulates the project\u2019s core mission of leveraging artificial intelligence to ensure water potability. As a brand, it conveys trust, innovation, and environmental responsibility, positioning the solution as a cutting-edge tool for water quality analysis and management. The logo effectively combines elements of technology and sustainability, emphasizing the project\u2019s commitment to solving global water challenges while ensuring the accuracy and reliability of its data-driven insights.</p> <p> </p>"},{"location":"#1-simplicity-and-clear-connection-with-water","title":"1. Simplicity and Clear Connection with Water","text":"<p>The central water droplet icon is universally recognized, instantly communicating the focus of the project on water potability. This symbol serves as a direct representation of the project\u2019s mission to ensure access to safe drinking water.</p> <ul> <li>Blue color: Evokes freshness, purity, and trust, aligning with the values of sustainability and technological advancement. It represents stability and reliability, key factors for a project handling critical environmental data.</li> </ul>"},{"location":"#2-geometric-and-modern-lines-representing-artificial-intelligence","title":"2. Geometric and Modern Lines: Representing Artificial Intelligence","text":"<p>The geometric lines surrounding the water droplet subtly represent artificial intelligence and machine learning. These modern shapes imply precision, control, and advanced technology.</p> <ul> <li>The clean, sharp lines suggest that the project is data-driven and powered by AI, reinforcing its technical sophistication and differentiation from traditional environmental monitoring systems.</li> </ul>"},{"location":"#3-the-blend-of-technology-and-sustainability","title":"3. The Blend of Technology and Sustainability","text":"<p>The integration of the water element with technology-centric lines and shapes visually represents the union of environmental sustainability and innovative AI solutions.</p> <ul> <li>This dual representation highlights the project\u2019s aim to solve environmental problems through advanced technologies and demonstrates its commitment to sustainable practices in the realm of water management.</li> </ul>"},{"location":"#4-integrated-branding-strategy","title":"4. Integrated Branding Strategy","text":"<p>The visual identity of Water Scan AI is designed to translate the project\u2019s business goals into graphic elements:</p> <ul> <li>Technological innovation (AI-driven data analysis)</li> <li>Environmental sustainability (focus on water quality and accessibility)</li> <li>Global impact (ensuring access to clean water)</li> </ul> <p>This direct connection between visual brand and project mission improves communication with stakeholders, partners, and users, while enhancing brand recognition. It positions Water Scan AI as a trustworthy, impactful, and cutting-edge solution in the field of water quality management.</p>"},{"location":"#features","title":"\ud83d\udd39 Features","text":"<p>\u2705 Programming Language: <code>Python</code>  \u2705 Structured using the <code>Factory Method Pattern</code> for trainer creation  \u2705 Uses the <code>Facade Pattern</code> in the logging module with MLflow (<code>MLFlowLogger</code>)  \u2705 Uses the <code>Singleton Pattern</code> to manage entries in the MLflow Registry  \u2705 Hyperparameter optimization with <code>Optuna</code>  \u2705 Class balancing with <code>SMOTE</code> (imblearn)  \u2705 Logging and tracking of experiments using <code>MLflow</code>  \u2705 Model registration and versioning with <code>MLflow Model Registry</code>  \u2705 Metric and artifact visualization with <code>matplotlib</code> and <code>MLflow</code>  \u2705 Evaluation using <code>scikit-learn</code> metrics  \u2705 Supports <code>Random Forest</code> models, with structure ready for XGBoost and LightGBM  \u2705 Code quality tools: <code>Pre-commit</code>, <code>Ruff</code>, <code>Black</code>, <code>Flake8</code>, <code>Isort</code>  \u2705 Task automation using <code>Makefile</code>  \u2705 Semantic version control with <code>bump2version</code>  \u2705 Automated testing with <code>Pytest</code> + <code>Pytest-Cov</code>  \u2705 Auto-generated documentation using <code>MkDocs</code> + <code>MkDocs Material</code>  \u2705 Automatic formatting and linting with <code>Ruff</code>, <code>Black</code>, and <code>Isort</code>  \u2705 Git hook support for code validation using <code>Pre-commit</code>  \u2705 Code structured using the <code>Singleton Pattern</code> for model registry management  \u2705 Modular and reusable architecture using <code>Poetry</code> for dependency management  \u2705 Continuous Integration (CI) with <code>GitHub Actions</code> for code quality validation, including:  \ud83d\udd39 - Automated quality checks on every <code>push</code> or <code>pull request</code> to the <code>main</code> branch  \ud83d\udd39 - Python environment setup with <code>Poetry</code>  \ud83d\udd39 - Automatic installation of development dependencies  \ud83d\udd39 - Execution of <code>make quality</code> rule to ensure code standardization </p>"},{"location":"#development-tools","title":"\ud83e\uddea Development Tools","text":"<ul> <li><code>ruff</code> \u2014 Linting and formatting</li> <li><code>black</code> \u2014 Code formatter</li> <li><code>isort</code> \u2014 Import ordering</li> <li><code>flake8</code> \u2014 Linting</li> <li><code>interrogate</code> \u2014 Docstring coverage checker</li> <li><code>pytest</code>, <code>pytest-cov</code> \u2014 Unit testing and coverage</li> <li><code>pre-commit</code> \u2014 Git hooks for automated code checks</li> <li><code>bump2version</code> \u2014 Semantic version control</li> <li><code>Optuna</code> \u2014 Hyperparameter optimization for model training</li> <li><code>MLflow</code> \u2014 Experiment tracking and model management</li> <li><code>Poetry</code> \u2014 Dependency management and virtual environment creation</li> <li><code>Makefile</code> \u2014 Task automation for project workflows</li> <li><code>Docker</code> \u2014 Containerization for environment consistency and service orchestration</li> <li><code>MinIO</code> \u2014 Object storage for MLflow artifacts</li> </ul>"},{"location":"#documentation-structure","title":"\ud83d\udd39 Documentation Structure","text":"<ul> <li>Installation: How to set up the environment.</li> <li>Project Usage: How to run the project.</li> <li>Project Structure: File structure explanation.</li> <li>Methodology (CRISP-DM): CRISP-DM methodology used in the project.</li> <li>Project Modules: Technical reference.</li> <li>Contributing: How to contribute to the project.</li> <li>Tests: Tests used in the project.</li> <li>Changelog: Version history.</li> </ul>"},{"location":"#crisp-dm-methodology-in-water-scan-ai","title":"CRISP-DM Methodology in Water Scan AI","text":"<p>The Water Scan AI project adopted the CRISP-DM (Cross-Industry Standard Process for Data Mining) methodology to structure the end-to-end development of a water potability prediction solution. Below is a description of each phase as applied to this project.</p>"},{"location":"#1-business-understanding","title":"\ud83d\udcd8 1. Business Understanding","text":"<p>The project began with a deep understanding of the water quality problem: predicting water potability. The strategic goal was to enhance public health and ensure safe water access through predictive analytics.</p> <ul> <li>Primary objective: Predict whether a water sample is potable (1) or non-potable (0) based on physical and chemical parameters.</li> </ul>"},{"location":"#2-data-understanding","title":"\ud83d\udcca 2. Data Understanding","text":"<p>The dataset was explored to understand its structure and identify patterns:</p> <ul> <li>EDA techniques like histograms, boxplots, KDE plots, and correlation heatmaps were applied.</li> <li>Observations included:</li> <li>Potable water tended to have higher pH and lower turbidity.</li> <li>Some water samples had significantly higher levels of sulfates and turbidity.</li> <li>Certain features, such as chloramines and conductivity, were strongly correlated with potability.</li> <li>Missing values and outliers were identified and addressed during data preprocessing.</li> </ul>"},{"location":"#3-data-preparation","title":"\ud83d\udee0 3. Data Preparation","text":"<p>In this phase, the dataset was cleaned and transformed:</p> <ul> <li>Missing values were handled using the median imputation technique.</li> <li>Categorical features were encoded, and numerical features were standardized.</li> <li>The target variable (<code>Potability</code>) was mapped to binary (0 or 1).</li> <li>SMOTE was applied to balance the classes.</li> <li>Train-test split was performed, ensuring stratification based on potability.</li> </ul>"},{"location":"#4-modeling","title":"\ud83e\udd16 4. Modeling","text":"<p>Several models were trained and compared:</p> <ul> <li>Random Forest</li> <li>XGBoost</li> </ul> <p>All models were evaluated with:</p> <ul> <li><code>Accuracy</code>, <code>F1-Score</code>, <code>Precision</code>, <code>Recall</code>, <code>ROC AUC</code></li> <li>Confusion matrices, feature importance, and learning curves were used for evaluation.</li> </ul>"},{"location":"#5-evaluation","title":"\u2705 5. Evaluation","text":"<p>The models were assessed both quantitatively and visually:</p> <ul> <li>Random Forest was the best performer, achieving high accuracy and stable performance across different evaluation metrics.</li> <li>Feature importance revealed that variables such as <code>ph</code>, <code>hardness</code>, and <code>conductivity</code> were most predictive of water potability.</li> </ul>"},{"location":"#summary","title":"\ud83c\udfaf Summary","text":"<p>CRISP-DM provided a clear, iterative roadmap to:</p> <ul> <li>Understand the water potability prediction problem</li> <li>Prepare, model, and evaluate data scientifically</li> <li>Deliver business-driven recommendations to improve water quality monitoring and ensure safe water access</li> </ul> <p>Water Scan AI is a modular, interpretable, and reproducible solution for predicting water potability, ensuring public health and environmental sustainability.</p>"},{"location":"changelog/","title":"\ud83d\udcdc Changelog","text":""},{"location":"changelog/#v101-2025-03-24","title":"v1.0.1 (2025-03-24)","text":"<p>\ud83d\udd3c Version update via <code>bump2version</code>.</p> <p>\ud83e\uddea Integration of new libraries for model experimentation and evaluation: - <code>Optuna</code> for hyperparameter optimization. - <code>imblearn</code> for balancing techniques like SMOTE. - <code>pytest</code>, <code>pytest-cov</code> for automated testing and coverage reports.</p> <p>\ud83e\uddf9 Code quality improvements: - Added tools: <code>black</code>, <code>isort</code>, <code>flake8</code>, <code>ruff</code>, and <code>interrogate</code>. - Configured <code>pre-commit</code> for automatic validations before commits.</p> <p>\ud83d\udcda Documentation enhancements: - Integrated with <code>mkdocs</code>, <code>mkdocs-material</code>, <code>mkdocstrings-python</code>, and visual themes. - Included charts and visualizations in the <code>assets/images/crisp_dm</code> directory.</p> <p>\u2699\ufe0f Development environment organization: - Using <code>Makefile</code> for automated commands. - Using <code>bump2version</code> for semantic version control. - Project now structured with <code>Poetry</code> and Python 3.11.</p> <p>\u2b05 Back to Home Page</p>"},{"location":"contributing/","title":"Contributing to Arxiv Scraping","text":""},{"location":"contributing/#contribution-requirements","title":"\ud83d\udd39 Contribution Requirements","text":"<ul> <li>Follow PEP 8 guidelines</li> <li>Run <code>pre-commit</code> before submitting PRs</li> </ul>"},{"location":"contributing/#how-to-contribute","title":"\ud83d\udd39 How to Contribute?","text":"<p>1\ufe0f\u20e3 Fork the repository</p> <p>2\ufe0f\u20e3 Clone your fork</p> <pre><code>git clone https://github.com/seu-usuario/water_scan_ai.git\n</code></pre> <p>3\ufe0f\u20e3 Create a branch for your feature</p> <p><code>git checkout -b feature-nova</code></p> <p>4\ufe0f\u20e3 Implement your change and run pre-commit <code>pre-commit run --all-files</code></p> <p>5\ufe0f\u20e3 Commit and submit a Pull Request</p> <p><code>git add .</code></p> <p><code>git commit -m \"Adicionando nova feature\"</code></p> <p><code>git push origin feature-nova</code></p> <p>\u2b05 Back to Home Page</p>"},{"location":"crisp_dm_stages/","title":"Introduction","text":"<p>In this water potability classification project, the CRISP-DM (Cross Industry Standard Process for Data Mining) methodology was adopted due to its well-defined, iterative structure and its wide recognition in the data science industry.</p> <p></p> <p>CRISP-DM guided all stages of the project according to the following:</p> <ul> <li>1) Business Understanding: The main goal was defined as predicting water potability based on physicochemical parameters.</li> <li>2) Data Understanding: An exploratory analysis was conducted to understand the structure, quality, and imbalance of the dataset.</li> <li>3) Data Preparation: Included handling missing values, applying SMOTE, and splitting the data into training and testing sets.</li> <li>4) Modeling: Models such as Random Forest and XGBoost were optimized using Optuna.</li> <li>5) Evaluation: Model performance was compared using metrics like accuracy, recall, and F1-score.</li> <li>6) Deployment: The best-performing model was registered in the MLflow Registry and is ready for production use.</li> </ul> <p>Choosing CRISP-DM ensured organization, reproducibility, and alignment between technical and business objectives, making it ideal for structured data science projects like this one.</p>"},{"location":"crisp_dm_stages/#part-1-business-understanding-problem-water-potability-prediction","title":"Part 1) Business Understanding (Problem): Water Potability Prediction","text":""},{"location":"crisp_dm_stages/#project-objective","title":"Project Objective","text":"<p>Develop a supervised classification model capable of predicting whether a water sample is potable (1) or not potable (0) based on physicochemical variables. This solution aims to support public policies in sanitation, health, and environmental monitoring, contributing directly to access to safe water, as recommended by the World Health Organization (WHO).</p>"},{"location":"crisp_dm_stages/#context","title":"Context","text":"<p>Access to safe drinking water is a fundamental human right and a crucial component of public health policies. Water quality has a direct impact on population health, hospital costs, and economic productivity. In many regions, improvements in supply systems and quality monitoring result in net economic benefits by reducing waterborne diseases.</p> <p>Based on a dataset of 3,276 observations from various water sources, this project seeks to predict water potability using 9 measurable variables that reflect the chemical, physical, and microbiological characteristics of water.</p>"},{"location":"crisp_dm_stages/#variable-description","title":"Variable Description","text":"Variable Description Recommended Range / Limit <code>ph</code> Measures the acid-base balance of water. Ideal range is 6.5 to 8.5. 6.5 \u2013 8.5 (WHO) <code>Hardness</code> Concentration of calcium and magnesium salts (hardness). \u2014 <code>Solids</code> Total Dissolved Solids (TDS). Indicates mineralization level. &lt; 500 mg/L (ideal), max. 1000 <code>Chloramines</code> Common disinfectant agent used in potable water. \u2264 4 mg/L <code>Sulfate</code> Naturally occurring substance found in various environments. 3 to 30 mg/L (normal), up to 1000 <code>Conductivity</code> Related to the amount of dissolved ions. \u2264 400 \u03bcS/cm <code>Organic_carbon</code> Represents natural or synthetic organic matter present in the water. &lt; 4 mg/L <code>Trihalomethanes</code> Byproducts of chlorine treatment. \u2264 80 ppm <code>Turbidity</code> Opacity caused by suspended particles. \u2264 5 NTU <code>Potability</code> Target variable. Indicates if the water is potable (1) or not (0). \u2014"},{"location":"crisp_dm_stages/#problem-nature","title":"Problem Nature","text":"<ul> <li>Type: Binary Classification (<code>0 = Not Potable</code>, <code>1 = Potable</code>)</li> <li>Target Variable: <code>Potability</code></li> <li>Predictor Variables: 9 continuous variables related to water quality</li> <li>Potential Challenge: Class imbalance</li> </ul>"},{"location":"crisp_dm_stages/#practical-applications","title":"Practical Applications","text":"<ul> <li>Automation of water treatment plants</li> <li>Real-time monitoring via sensors</li> <li>Alert systems for public managers and municipalities</li> <li>Decision support in contexts of water crises or environmental disasters</li> </ul>"},{"location":"crisp_dm_stages/#part-2-data-understanding","title":"Part 2) Data Understanding","text":""},{"location":"crisp_dm_stages/#21-data-source","title":"2.1) Data Source","text":"<p>The data used in this project was obtained from the Dataset (Water Quality) on Kaggle. The dataset used in this project is provided in the file <code>water_potability.csv</code>, with an approximate size of 525 KB, containing 3,276 records and 10 columns, each representing a physicochemical variable or the water potability label.</p> <p>This dataset simulates samples from various water sources and aims to represent diverse water quality scenarios, based on parameters defined by regulatory agencies such as the WHO (World Health Organization) and the EPA (United States Environmental Protection Agency).</p>"},{"location":"crisp_dm_stages/#column-description","title":"Column Description","text":"# Column Unit Description 1 <code>ph</code> \u2014 Measure of the acidity or alkalinity of water (scale from 0 to 14). 2 <code>Hardness</code> mg/L Water's ability to precipitate soap, related to the presence of calcium and magnesium. 3 <code>Solids</code> ppm Total dissolved solids. High concentration affects water taste and color. 4 <code>Chloramines</code> ppm Concentration of chloramines, common disinfectants in public water systems. 5 <code>Sulfate</code> mg/L Amount of dissolved sulfate, naturally present in soils and rocks. 6 <code>Conductivity</code> \u00b5S/cm Electrical conductivity of water, related to the amount of dissolved ions. 7 <code>Organic_carbon</code> ppm Amount of organic carbon, from natural or synthetic organic matter. 8 <code>Trihalomethanes</code> \u00b5g/L Byproducts of water chlorination, potentially toxic at high concentrations. 9 <code>Turbidity</code> NTU Degree of water cloudiness caused by suspended particles. 10 <code>Potability</code> Binary Target variable. Indicates whether the water is potable (<code>1</code>) or not potable (<code>0</code>)."},{"location":"crisp_dm_stages/#notes-on-data-collection","title":"Notes on Data Collection","text":"<ul> <li>The dataset does not include geographic or temporal identifiers, indicating that the data was either anonymized or simulated for academic or benchmarking purposes.</li> <li>Variable units are standardized according to technical specifications:</li> <li>ppm (parts per million)</li> <li>mg/L (milligrams per liter)</li> <li>\u00b5g/L (micrograms per liter)</li> <li>\u00b5S/cm (microsiemens per centimeter)</li> <li>NTU (Nephelometric Turbidity Unit)</li> <li>Missing values (<code>NaN</code>) are present in some variables and will be handled during preprocessing.</li> <li>The target variable (<code>Potability</code>) is binary, where:</li> <li><code>1</code> \u2192 potable water</li> <li><code>0</code> \u2192 non-potable water</li> </ul>"},{"location":"crisp_dm_stages/#identified-potential-challenges","title":"Identified Potential Challenges","text":"<ul> <li>Missing values: Some variables contain missing data, which requires imputation.</li> <li>Class imbalance: The distribution between potable and non-potable classes may be uneven, affecting model performance.</li> </ul>"},{"location":"crisp_dm_stages/#part-22-exploratory-data-analysis-eda","title":"Part 2.2) Exploratory Data Analysis (EDA)","text":""},{"location":"crisp_dm_stages/#221-dataset-overview","title":"2.2.1) Dataset Overview","text":"<ul> <li>The dataset contains 3,276 rows and 10 columns.</li> <li>Each row represents a water sample with physicochemical measurements and the corresponding potability label (<code>0</code> or <code>1</code>).</li> </ul>"},{"location":"crisp_dm_stages/#initial-observations","title":"Initial Observations","text":"<ul> <li>Missing values: We can already observe <code>NaN</code> values in some columns such as <code>ph</code> and <code>Sulfate</code>, indicating the need for missing data handling during preprocessing.</li> <li>Data scale: Some variables have values with different orders of magnitude:</li> <li><code>Solids</code>, <code>Conductivity</code>, <code>Sulfate</code> \u2192 very high values</li> <li><code>Turbidity</code>, <code>ph</code>, <code>Organic_carbon</code> \u2192 lower values</li> <li>This emphasizes the importance of scaling/normalization before modeling.</li> <li>Target variable (<code>Potability</code>): All 5 displayed samples have a value of <code>0</code>, suggesting that the sample might be imbalanced \u2014 which will be further investigated in the target distribution analysis.</li> </ul>"},{"location":"crisp_dm_stages/#partial-conclusion-of-the-eda-substage","title":"Partial Conclusion of the EDA Substage","text":"<p>The dataset overview reveals that the data is well-structured, but presents common real-world challenges, such as missing values, heterogeneous scales, and potential imbalance. These issues will be addressed in the upcoming stages of the predictive modeling pipeline.</p>"},{"location":"crisp_dm_stages/#222-checking-data-types-and-missing-values","title":"2.2.2) Checking Data Types and Missing Values","text":""},{"location":"crisp_dm_stages/#data-structure","title":"Data Structure","text":"<ul> <li>The dataset has 3,276 rows and 10 columns.</li> <li>All predictor variables are of type <code>float64</code>.</li> <li>The target variable (<code>Potability</code>) is of type <code>int64</code>, with binary values (0 or 1).</li> </ul>"},{"location":"crisp_dm_stages/#missing-values-analysis","title":"Missing Values Analysis","text":"Column Missing Values Percentage (%) <code>ph</code> 491 14.99% (~15%) <code>Sulfate</code> 781 23.85% (high) <code>Trihalomethanes</code> 162 4.94% (relatively low) Other columns 0 \u2014"},{"location":"crisp_dm_stages/#observations","title":"Observations:","text":"<ul> <li>Three columns contain missing values: <code>ph</code>, <code>Sulfate</code>, and <code>Trihalomethanes</code>.</li> <li>Missing data is concentrated in physicochemical attributes, possibly due to sensor failures or unperformed measurements.</li> <li>Columns such as <code>Hardness</code>, <code>Solids</code>, <code>Chloramines</code>, <code>Conductivity</code>, <code>Organic_carbon</code>, <code>Turbidity</code>, and <code>Potability</code> are complete.</li> </ul>"},{"location":"crisp_dm_stages/#implications-for-preprocessing","title":"Implications for Preprocessing","text":"Column Suggested Imputation Strategy <code>ph</code> Impute using the median <code>Sulfate</code> Impute using the median <code>Trihalomethanes</code> Impute using the median <p>\ud83d\udca1 Since the data is continuous and the percentage of missing values does not exceed 25%, adding values (imputation) is preferable to dropping rows.</p>"},{"location":"crisp_dm_stages/#insights-from-the-eda-substage","title":"Insights from the EDA Substage","text":"<p>The missing values analysis shows that the dataset is mostly complete, but requires special attention to three columns with missing data. This issue will be addressed in the data preprocessing stage, ensuring dataset consistency before modeling.</p>"},{"location":"crisp_dm_stages/#223-missing-values-visualization","title":"2.2.3) Missing Values Visualization","text":"<p>The image above, generated using the function <code>missingno.matrix(df)</code>, provides a graphical visualization of missing data patterns in the dataset.</p>"},{"location":"crisp_dm_stages/#visual-interpretation","title":"Visual Interpretation","text":"<ul> <li>Columns with white lines represent missing values.</li> <li>Columns with solid black fill contain no missing values.</li> <li>Three columns have missing data:</li> <li><code>ph</code> (column 0)</li> <li><code>Sulfate</code> (column 4)</li> <li><code>Trihalomethanes</code> (column 8)</li> </ul>"},{"location":"crisp_dm_stages/#confirmation-with-numerical-data","title":"Confirmation with Numerical Data","text":"Column Missing Values % of Total (3,276) <code>ph</code> 491 14.99% <code>Sulfate</code> 781 23.85% <code>Trihalomethanes</code> 162 4.94% Other columns 0 0%"},{"location":"crisp_dm_stages/#key-insights","title":"Key Insights","text":"<ul> <li>No apparent visual correlation between missing values across variables: each sample seems to have isolated gaps (not clustered).</li> <li>Columns <code>Hardness</code>, <code>Solids</code>, <code>Chloramines</code>, <code>Conductivity</code>, <code>Organic_carbon</code>, <code>Turbidity</code>, and <code>Potability</code> are complete (100% of values present).</li> <li>The missing data is randomly distributed across rows, which suggests MCAR (Missing Completely At Random) \u2014 meaning that the missingness is not dependent on observed data.</li> </ul>"},{"location":"crisp_dm_stages/#recommended-handling-strategies","title":"\ud83d\udee0\ufe0f Recommended Handling Strategies","text":"<p>Removing entire rows is not recommended, as it would result in the loss of up to 23.85% of the dataset, which would harm model learning.</p>"},{"location":"crisp_dm_stages/#insights-from-the-eda-substage_1","title":"Insights from the EDA Substage","text":"<p>The visualization confirms the previous diagnosis: the dataset contains missing values located in three specific columns. Since the missing data is sparse and relatively low in two variables, and moderate in <code>Sulfate</code>, median imputation will be applied during preprocessing to preserve data volume and integrity.</p>"},{"location":"crisp_dm_stages/#224-descriptive-statistics","title":"2.2.4) Descriptive Statistics","text":"<p>The table above summarizes the main statistics of central tendency, dispersion, and range for each continuous variable in the dataset.</p>"},{"location":"crisp_dm_stages/#insights-from-the-eda-substage_2","title":"Insights from the EDA Substage","text":"<p>The descriptive statistics confirm the need to handle missing values. Understanding the distribution and limits of variables also helps guide decisions on feature engineering and attribute selection in the modeling pipeline.</p>"},{"location":"crisp_dm_stages/#225-target-variable-distribution","title":"2.2.5) Target Variable Distribution","text":"<p>The target variable <code>Potability</code> indicates whether the water is potable (1) or not potable (0).</p>"},{"location":"crisp_dm_stages/#graph-observations","title":"Graph Observations","text":"<ul> <li>The distribution is asymmetric:</li> <li>Class <code>0</code> (Not Potable): approximately 2,000 samples</li> <li>Class <code>1</code> (Potable): approximately 1,200 samples</li> </ul>"},{"location":"crisp_dm_stages/#approximate-proportions","title":"Approximate Proportions:","text":"<ul> <li>Class 0 (Not Potable): ~61%</li> <li>Class 1 (Potable): ~39%</li> </ul>"},{"location":"crisp_dm_stages/#implications-for-modeling","title":"Implications for Modeling","text":"Impact Consequence Imbalanced classes Models tend to favor the majority class Accuracy can be misleading May appear high even with poor performance on the minority class F1-score and AUC more relevant Metrics like F1, Recall, and ROC AUC should be prioritized"},{"location":"crisp_dm_stages/#recommended-strategies","title":"Recommended Strategies","text":"<ol> <li>Balancing with SMOTE (Synthetic Minority Over-sampling Technique)</li> <li>Generates synthetic samples of the minority class</li> <li>Preserves the full dataset and improves generalization</li> <li> <p>Ideal before training the model</p> </li> <li> <p>Additional alternatives (if needed):</p> </li> <li>Use Class Weights in models like <code>LogisticRegression</code>, <code>RandomForestClassifier</code>, and <code>XGBoost</code></li> </ol>"},{"location":"crisp_dm_stages/#insights-from-the-eda-substage_3","title":"Insights from the EDA Substage","text":"<p>The visualization confirms the need to handle class imbalance. To ensure that the model learns fairly from both classes, the use of SMOTE (Synthetic Minority Over-sampling Technique) will be essential in the upcoming preprocessing and modeling stages.</p>"},{"location":"crisp_dm_stages/#226-percentage-proportion-of-the-target-class","title":"2.2.6) Percentage Proportion of the Target Class","text":"<p>The <code>Potability</code> variable represents the model's target class, indicating whether a water sample is: - <code>0</code>: Not Potable - <code>1</code>: Potable</p>"},{"location":"crisp_dm_stages/#percentage-distribution","title":"Percentage Distribution","text":"Class Description Proportion (%) <code>0</code> Not Potable 60.99% <code>1</code> Potable 39.01%"},{"location":"crisp_dm_stages/#interpretation","title":"Interpretation","text":"<ul> <li>There is a moderate imbalance between the classes.</li> <li>The majority class (<code>0</code>, not potable) accounts for approximately 61% of the samples, while the minority class (<code>1</code>, potable) represents about 39%.</li> <li>Although not an extreme imbalance, it can negatively affect model performance, especially in recall and F1-score for the minority class (<code>1</code> \u2013 potable water).</li> </ul>"},{"location":"crisp_dm_stages/#recommended-actions","title":"Recommended Actions","text":"Technique Application SMOTE Synthetically increase the minority class"},{"location":"crisp_dm_stages/#insights-from-the-eda-substage_4","title":"Insights from the EDA Substage","text":"<p>The analysis confirms the class imbalance, with a predominance of non-potable samples. The use of class rebalancing techniques is recommended to avoid prediction bias and ensure a fair and robust model for detecting potable water, which is the class of greatest social and public health interest.</p>"},{"location":"crisp_dm_stages/#227-histograms-to-understand-variable-distribution","title":"2.2.7) Histograms to Understand Variable Distribution","text":"<p>The histograms provide a clear view of the statistical distribution of continuous variables. This step is essential to guide decisions on normalization, transformation, and model selection.</p>"},{"location":"crisp_dm_stages/#general-observations","title":"General Observations","text":"<ul> <li>Most variables show an approximately normal or symmetric distribution.</li> <li>The absence of significant skewness indicates that many algorithms, such as Logistic Regression, KNN, and Random Forest, should perform well without additional transformations.</li> <li>Variables do not appear to have many extreme outliers, reducing the need for aggressive treatments.</li> </ul>"},{"location":"crisp_dm_stages/#individual-analysis","title":"Individual Analysis","text":"Variable Observation <code>ph</code> Slightly symmetric distribution centered around 7 <code>Hardness</code> Symmetric and well-behaved distribution <code>Solids</code> Symmetric with a slight right tail (mild skew) <code>Chloramines</code> Slightly left-skewed, but still acceptable <code>Sulfate</code> Approximates normal, with mild concentration to the right <code>Conductivity</code> Slight right skew, no major anomalies <code>Organic_carbon</code> Slightly skewed, centered around 14 <code>Trihalomethanes</code> Reasonably symmetric distribution <code>Turbidity</code> Slight concentration between 3 and 4, similar to normal shape"},{"location":"crisp_dm_stages/#insights-from-the-eda-substage_5","title":"Insights from the EDA Substage","text":"<p>The variable distributions are suitable for direct use in Machine Learning models. With simple standardization, the data will be ready for algorithms that assume normality. This analysis reinforces that the dataset is statistically stable and well-behaved, with minimal need for complex transformations.</p>"},{"location":"crisp_dm_stages/#228-boxplots-to-detect-outliers","title":"2.2.8) Boxplots to Detect Outliers","text":"<p>In this step, boxplots were used to compare the distribution of continuous variables across the target variable <code>Potability</code> (0 = Not Potable, 1 = Potable) and to identify outliers.</p>"},{"location":"crisp_dm_stages/#observations-by-variable","title":"Observations by Variable","text":"Variable Outliers? Difference Between Classes? Observations <code>ph</code> Yes Slight Outliers on both sides; potable samples tend to have slightly higher pH. <code>Hardness</code> Yes Very slight Similar distributions; some high outliers. <code>Solids</code> Yes Virtually none Very high outliers; similar distribution between classes. <code>Chloramines</code> Yes Slight Potable samples show slightly higher average values. <code>Sulfate</code> Yes Slight Potable water tends to have a lower mean and greater spread. <code>Conductivity</code> Yes Slight Slight increase in the median for potable samples. <code>Organic_carbon</code> Yes None Nearly identical distributions. <code>Trihalomethanes</code> Yes None Outliers in both classes; no apparent difference. <code>Turbidity</code> Yes Slight Slight median increase in potable samples."},{"location":"crisp_dm_stages/#about-the-outliers","title":"About the Outliers","text":"<ul> <li>All variables present visible outliers.</li> <li>Most outliers are above the upper limit (Q3 + 1.5 * IQR).</li> <li>The outliers are not extreme enough to compromise modeling, but it is worth considering:</li> <li>Keeping the outliers, if plausible (especially for environmental variables).</li> <li>Robust transformations, such as <code>RobustScaler</code>, if using sensitive models.</li> </ul>"},{"location":"crisp_dm_stages/#insights-from-the-eda-substage_6","title":"Insights from the EDA Substage","text":"<p>The boxplot analysis shows that the dataset contains outliers in all variables, but without severe impact on class separation. Differences between classes are subtle, meaning the model will need to combine multiple variables to achieve good performance \u2014 reinforcing the value of non-linear models such as Random Forest or XGBoost.</p>"},{"location":"crisp_dm_stages/#229-correlation-map-between-variables","title":"2.2.9) Correlation Map Between Variables","text":"<p>The heatmap shown displays Pearson correlation coefficients between all variables in the dataset, including the target variable <code>Potability</code>.</p>"},{"location":"crisp_dm_stages/#general-observations_1","title":"General Observations","text":"<ul> <li>Most correlations are centered around 0, indicating that variables are weakly correlated with one another.</li> <li>This is advantageous for tree-based models (like Random Forest and XGBoost), which are not sensitive to multicollinearity.</li> </ul>"},{"location":"crisp_dm_stages/#correlation-with-the-target-variable-potability","title":"Correlation with the Target Variable (<code>Potability</code>)","text":"Variable Correlation with <code>Potability</code> <code>Solids</code> +0.03 <code>Chloramines</code> +0.02 <code>Trihalomethanes</code> +0.01 <code>Hardness</code> -0.01 <code>Sulfate</code> -0.02 <code>Conductivity</code> -0.01 <code>Organic_carbon</code> -0.03 <code>Turbidity</code> +0.01 <code>ph</code> \u2248 0.00 <p>Notes: - No variable shows strong correlation with the target. This suggests:   - The relationship with potability is likely non-linear;   - Modeling should consider combinations and interactions between variables to achieve good predictive performance.</p>"},{"location":"crisp_dm_stages/#correlation-between-predictor-variables","title":"Correlation Between Predictor Variables","text":"Variable Pair Correlation Observation <code>Sulfate</code> &amp; <code>Solids</code> -0.17 Mild negative correlation <code>ph</code> &amp; <code>Solids</code> -0.09 Weak negative correlation <code>ph</code> &amp; <code>Hardness</code> +0.08 Weak positive correlation Other pairs ~0.00 to \u00b10.05 Negligible correlation <p>Notes: There is no evidence of multicollinearity, and all variables can be kept in the model without the need for removal due to redundancy.</p>"},{"location":"crisp_dm_stages/#implications-for-modeling_1","title":"Implications for Modeling","text":"Strategy Justification Non-linear models Data suggests low linearity with the target variable Feature engineering Interactions can improve model performance No strong collinearity All variables can be used as input"},{"location":"crisp_dm_stages/#insights-from-the-eda-substage_7","title":"Insights from the EDA Substage","text":"<p>The correlation map shows that the dataset is statistically stable, with no problematic collinearity, but also no variables strongly correlated with water potability. This reinforces the importance of using non-linear and robust models, as well as combining variables during feature engineering.</p>"},{"location":"crisp_dm_stages/#2210-kde-plots-density-by-class","title":"2.2.10) KDE Plots (Density) by Class","text":"<p>In this step, Kernel Density Estimation (KDE) plots were used to visually compare the distribution of continuous variables between the two classes of the target variable <code>Potability</code>: - Potable (<code>1</code>) \u2013 blue line - Not Potable (<code>0</code>) \u2013 orange line</p>"},{"location":"crisp_dm_stages/#variable-by-variable-analysis","title":"Variable-by-Variable Analysis","text":"Variable Difference Between Classes? Relevant Observations <code>ph</code> Slight Potable water tends to have a pH closer to 7. Slight visible deviation. <code>Hardness</code> Very slight Almost overlapping distributions. <code>Solids</code> None Nearly identical curves. <code>Chloramines</code> Slight Potable water shows a slightly right-shifted distribution. <code>Sulfate</code> Slight Potable water values are slightly more spread. <code>Conductivity</code> Slight Potable class leans slightly to the right (higher average conductivity). <code>Organic_carbon</code> Very slight Potable class distribution is more concentrated around the mean. <code>Trihalomethanes</code> None Distributions are nearly identical. <code>Turbidity</code> Very slight Potable water slightly more concentrated between 3.5 and 4.5 NTU."},{"location":"crisp_dm_stages/#general-interpretation","title":"General Interpretation","text":"<ul> <li>The variables individually do not provide strong class separability.</li> <li>However, small differences combined across multiple variables may help a non-linear model to identify effective decision boundaries.</li> <li>Similar distributions reinforce that this is a non-trivial problem, requiring algorithms capable of capturing complex patterns.</li> </ul>"},{"location":"crisp_dm_stages/#modeling-implications","title":"Modeling Implications","text":"Strategy Justification Ensemble-based models Random Forest or XGBoost can capture interactions between variables Feature engineering Creating or crossing variables may reveal hidden patterns Feature selection techniques Evaluate combinations with higher discriminative power Use of PCA (optional) May assist in dimensionality reduction and visualization of potential clusters"},{"location":"crisp_dm_stages/#insights-da-subetapa-do-eda","title":"Insights da subetapa do EDA","text":"<p>Os KDE plots confirmam que as vari\u00e1veis n\u00e3o s\u00e3o fortemente discriminat\u00f3rias de forma isolada, mas podem ser valiosas quando combinadas. A modelagem deve explorar rela\u00e7\u00f5es multivariadas e aplicar algoritmos capazes de captar intera\u00e7\u00f5es n\u00e3o lineares.</p>"},{"location":"crisp_dm_stages/#insights-from-the-eda-substage_8","title":"Insights from the EDA Substage","text":"<p>The KDE plots confirm that the variables are not strongly discriminatory in isolation, but can be valuable when combined. Modeling should explore multivariate relationships and apply algorithms capable of capturing non-linear interactions.</p>"},{"location":"crisp_dm_stages/#part-3-data-preparation","title":"Part 3) Data Preparation","text":""},{"location":"crisp_dm_stages/#31-handling-missing-values","title":"3.1) Handling Missing Values","text":"<p>The first step in data preparation involved identifying and handling missing values in the dataset. The presence of NaN values can negatively impact machine learning model performance and distort statistical analyses and metrics. An initial check for missing values per column was performed using the command <code>df.isnull().sum()</code>.</p> <p>To address this issue, median imputation was applied to each numerical column using the method <code>df.fillna(df.median(), inplace=True)</code>. This approach is robust against outliers and helps preserve the overall data distribution. After imputation, it was verified that no missing values remained in the dataset.</p>"},{"location":"crisp_dm_stages/#32-splitting-the-data-into-training-and-testing-sets","title":"3.2) Splitting the Data into Training and Testing Sets","text":"<p>With the dataset now complete, the data was split into independent variables (X) and the target variable (y), where the target is the <code>Potability</code> column, indicating whether the water is potable (1) or not (0).</p> <p>The <code>train_test_split</code> function from the sklearn library was then used to divide the data into training (80%) and testing (20%) sets. The parameter <code>stratify=y</code> was used to preserve the original class proportions (potable vs. non-potable) in both sets, ensuring a representative split. Additionally, a seed (<code>random_state=42</code>) was set for reproducibility.</p>"},{"location":"crisp_dm_stages/#33-applying-smote","title":"3.3) Applying SMOTE","text":"<p>Due to the imbalance in the target variable \u2014 that is, an unequal distribution between classes \u2014 the SMOTE (Synthetic Minority Over-sampling Technique) method was applied to generate synthetic samples of the minority class in the training set.</p> <p>Using SMOTE allows for training more robust models, minimizing bias toward the majority class and improving performance on imbalance-sensitive metrics such as recall and F1-score. SMOTE was applied only to the training data (<code>X_train</code>, <code>y_train</code>) to avoid data leakage and preserve the integrity of the test evaluation.</p>"},{"location":"crisp_dm_stages/#41-rationale-for-model-testing-random-forest-and-xgboost-with-optuna-optimization","title":"4.1) Rationale for Model Testing: Random Forest and XGBoost with Optuna Optimization","text":""},{"location":"crisp_dm_stages/#why-random-forest-and-xgboost","title":"Why Random Forest and XGBoost?","text":""},{"location":"crisp_dm_stages/#random-forest-classifier","title":"Random Forest Classifier","text":"<ul> <li>A robust model based on bagging (bootstrap + decision trees).</li> <li>Ideal for data with:</li> <li>Outliers (as seen in the boxplots)</li> <li>Weak correlations between predictors and the target (as seen in the heatmap)</li> <li>Poorly discriminative class distributions (as seen in the KDE plots)</li> <li>Performs well even without aggressive normalization.</li> <li>Low risk of overfitting when properly tuned (number of trees, depth, etc.).</li> </ul>"},{"location":"crisp_dm_stages/#xgboost-classifier","title":"XGBoost Classifier","text":"<ul> <li>A gradient boosting model that is highly efficient and accurate.</li> <li>Capable of capturing complex patterns and non-linear interactions between variables.</li> <li>Works well on tabular data with imbalanced classes (as in this project).</li> <li>Native support for missing value handling and L1/L2 regularization.</li> <li>Often outperforms other tree-based models in structured data benchmarks.</li> </ul>"},{"location":"crisp_dm_stages/#why-use-optuna","title":"Why Use Optuna?","text":"<ul> <li>Optuna is a modern hyperparameter optimization library using intelligent Bayesian search.</li> <li>Unlike exhaustive search (GridSearch) or random search (RandomSearch), Optuna:</li> <li>Reduces computational time.</li> <li>Focuses on the most promising regions of the search space.</li> <li> <p>Works well even with limited computational resources.</p> </li> <li> <p>For this project, the complexity of tuning hyperparameters for Random Forest and XGBoost makes Optuna essential to achieve the best possible performance.</p> </li> </ul>"},{"location":"crisp_dm_stages/#selected-metric-accuracy","title":"Selected Metric: Accuracy","text":"<ul> <li>Accuracy is a useful initial metric for evaluating models in binary classification problems.</li> <li>Justifications:</li> <li>The class imbalance is moderate (\u2248 61% vs 39%), not severe.</li> <li>The metric is simple to interpret and compare.</li> <li>It served as a baseline to compare raw performance between models using the best hyperparameters.</li> </ul>"},{"location":"crisp_dm_stages/#observations_1","title":"Observations:","text":"<p>The combined choice of Random Forest and XGBoost models, both optimized with Optuna and evaluated using accuracy, is justified by the problem context: - Continuous data with low direct correlation to the target variable; - Subtle differences between class distributions; - Need for generalization with strong predictive capacity; - Efficient and automated hyperparameter search using Optuna.</p> <p>This approach balances performance, robustness, and interpretability, making it highly suitable for the water potability prediction challenge.</p>"},{"location":"crisp_dm_stages/#42-hyperparameter-optimization-with-optuna","title":"4.2) Hyperparameter Optimization with Optuna","text":"<p>To ensure the best possible performance of each algorithm, the Optuna library was used for efficient hyperparameter search. Each algorithm had its own objective function defined, with return values based on accuracy over the test set:</p> <ul> <li> <p>Random Forest: search over <code>n_estimators</code>, <code>max_depth</code>, <code>min_samples_split</code>;</p> </li> <li> <p>XGBoost: search over <code>n_estimators</code>, <code>max_depth</code>, <code>learning_rate</code>;</p> </li> </ul> <p>Each study was optimized for 100 iterations (<code>n_trials=100</code>), and the best sets of hyperparameters were selected for final model training.</p>"},{"location":"crisp_dm_stages/#part-5-model-evaluation","title":"Part 5) Model Evaluation","text":""},{"location":"crisp_dm_stages/#51-model-evaluation","title":"5.1) Model Evaluation","text":"<p>After optimization, the Random Forest and XGBoost models were retrained using the best parameters found. Both were evaluated using the following metrics:</p> <ul> <li>Accuracy</li> <li>Precision, Recall, and F1-Score per class</li> <li>Weighted and macro averages for overall comparison</li> </ul> Model Accuracy Precision (Class 1) Recall (Class 1) F1-Score (Class 1) Random Forest 0.67 0.59 0.52 0.55 XGBoost 0.66 0.57 0.54 0.56 <p>It is observed that the Random Forest model achieved higher overall accuracy (0.67) and better precision when classifying samples as potable. Although XGBoost achieved a slightly better recall for class 1, Random Forest strikes a better balance between precision and recall, resulting in a competitive F1-Score.</p>"},{"location":"crisp_dm_stages/#52-best-model-selection","title":"5.2) Best Model Selection","text":"<p>Based on performance comparison, the Random Forest model optimized with Optuna was chosen as the final model for this project. Despite the close results, its greater ability to generalize to the minority class makes it more suitable for the project\u2019s goal: to identify potable water samples with greater confidence.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#about-the-project","title":"\ud83d\udd39 About the Project","text":"<p>\ud83d\udca7 Water Scan AI is a Machine Learning project that classifies water potability using preprocessing techniques, class balancing, hyperparameter optimization, and model versioning with MLflow.</p> <ul> <li>Project Name: <code>water_scan_ai</code></li> <li>Author: <code>tralencar</code></li> <li>Version: \"1.0.1\"</li> <li>License: <code>MIT</code></li> <li>Keywords: <code>quality</code>, <code>water</code></li> <li>Data Source: Dataset (Water Quality) from Kaggle.</li> </ul>"},{"location":"installation/#prerequisites","title":"\ud83d\udd39 Prerequisites","text":"<p>Before installing the project, make sure your environment meets the following requirements:</p> <ul> <li>Python <code>&gt;=3.9, &lt;4.0</code></li> <li>Git installed</li> <li>Poetry for dependency management</li> <li>Make (Makefile support is included in dependencies)</li> </ul>"},{"location":"installation/#installing-dependencies","title":"\ud83d\udd39 Installing Dependencies","text":""},{"location":"installation/#1-clone-the-repository","title":"1\ufe0f\u20e3 Clone the repository","text":"<pre><code>git clone https://github.com/tralencar/water_scan_ai.git\ncd water_scan_ai\n</code></pre>"},{"location":"installation/#2-install-poetry-if-not-already-installed","title":"2\ufe0f\u20e3 Install Poetry (if not already installed)","text":"<p><code>pip install poetry</code></p>"},{"location":"installation/#3-configure-poetry-to-create-virtual-environments-in-the-project-folder","title":"3\ufe0f\u20e3 Configure Poetry to create virtual environments in the project folder","text":"<p><code>poetry config virtualenvs.in-project true</code></p> <p>\ud83d\udccc Note: * This will create a <code>.venv/</code> folder inside the project directory, helping with isolation and portability.</p>"},{"location":"installation/#4-activate-the-virtual-environment","title":"4\ufe0f\u20e3 Activate the virtual environment","text":"<p><code>poetry shell</code></p>"},{"location":"installation/#5-install-dependencies","title":"5\ufe0f\u20e3 Install dependencies","text":"<p><code>poetry install</code></p> <p>\ud83d\udccc Notes: </p> <ul> <li>This will install all libraries listed in the <code>pyproject.toml</code>, including: </li> <li>Data scraping and processing: <code>pandas</code>, <code>seaborn</code> </li> <li>Machine Learning and optimization: <code>scikit-learn</code>, <code>xgboost</code>, <code>lightgbm</code>, <code>optuna</code>, <code>imblearn</code> </li> <li>Experiment tracking and versioning: <code>mlflow</code> </li> <li>Interactive notebooks: <code>jupyter</code> </li> <li>Code quality and formatting: <code>black</code>, <code>isort</code>, <code>flake8</code>, <code>ruff</code>, <code>interrogate</code> </li> <li>Testing: <code>pytest</code>, <code>pytest-cov</code> </li> <li>Version control: <code>bump2version</code> </li> <li>Pre-commit hooks: <code>pre-commit</code> </li> <li>Documentation: <code>mkdocs</code>, <code>mkdocs-material</code>, <code>mkdocstrings-python</code>, <code>pymdown-extensions</code>, <code>mkdocs-bootstrap386</code></li> </ul>"},{"location":"installation/#pre-commit-configuration","title":"\ud83d\udd39 Pre-commit Configuration","text":"<p>Pre-commit helps maintain code quality. To enable it, run:</p> <p><code>poetry run pre-commit install</code></p> <p>\ud83d\udccc Note: </p> <ul> <li>From now on, every time you make a commit, <code>pre-commit</code> hooks will run automatically.</li> </ul>"},{"location":"installation/#verifying-the-installation","title":"\ud83d\udd39 Verifying the Installation","text":"<p>To ensure everything was installed correctly, run:</p> <p><code>poetry run python -c \"import pandas; print('Installation successful!')\"</code></p> <p>\ud83d\udccc Note: </p> <ul> <li>If the message \"Installation successful!\" appears, everything is properly configured.</li> </ul>"},{"location":"installation/#minio-mlflow-integration-setup","title":"\ud83d\udd39 MinIO + MLflow Integration Setup","text":"<p>To ensure secure model versioning, the <code>Water Scan AI</code> project uses MinIO as the artifact store for MLflow, simulating an S3-compatible interface. Model and metadata persistence is handled by:</p> <ul> <li>MinIO (S3-like storage for artifacts such as <code>.pkl</code>, <code>.onnx</code> models, images, metrics, etc.)</li> <li>PostgreSQL (backend store for logs, parameters, and experiment runs)</li> </ul>"},{"location":"installation/#creating-an-access-key-in-minio","title":"\ud83d\udd39 Creating an Access Key in MinIO","text":"<p>Access the MinIO dashboard (locally at <code>http://localhost:9001</code>) and create a new access key in the Access Keys menu. Below is an example of the MinIO access screen and the corresponding environment variable configuration:</p> <p></p> <p>\u26a0\ufe0f Make sure the environment variables <code>AWS_ACCESS_KEY_ID</code> and <code>AWS_SECRET_ACCESS_KEY</code> match those in the <code>tracking_server</code> section of your <code>docker-compose.yml</code>.</p>"},{"location":"installation/#creating-a-bucket-in-minio","title":"\ud83d\udd39 Creating a Bucket in MinIO","text":"<p>After configuring the access credentials, you need to create a bucket in MinIO to store MLflow experiment artifacts (models, metrics, images, logs, etc.).</p>"},{"location":"installation/#step-1-click-create-bucket","title":"Step 1: Click \"Create Bucket\"","text":"<p>Open the MinIO interface, go to the Buckets section in the sidebar, and click the Create Bucket button as shown below:</p> <p>Follow these steps according to the image:</p> <ul> <li>Access the MinIO admin panel at the local link</li> <li>In the sidebar, click Buckets</li> <li>Click the Create Bucket button (as highlighted below)</li> <li>Name the bucket <code>mlflow</code> (or another name, but be sure it matches the <code>artifacts-destination</code> variable defined in <code>docker-compose.yml</code>)</li> </ul> <p></p>"},{"location":"installation/#step-2-enter-the-bucket-name","title":"Step 2: Enter the Bucket Name","text":"<p>Suggested name: <code>mlflow</code></p> <p></p> <p>\ud83d\udccc Notes (Important rules for bucket naming):</p> <ul> <li>Must be in lowercase</li> <li>No spaces</li> <li>Avoid special characters</li> <li>Use a simple name like <code>mlflow</code>, <code>experiments</code>, <code>models</code>, etc.</li> </ul> <p>\u26a0\ufe0f Make sure the bucket name exactly matches the <code>artifacts-destination</code> value and the bucket name configured in the <code>tracking_server</code> of <code>docker-compose.yml</code>.</p> <p>\u2705 MLflow is now ready to store and version artifacts directly in the <code>mlflow</code> bucket on MinIO!</p> <p>\u2b05 Back to Home Page</p>"},{"location":"module_1/","title":"\ud83d\udcda Technical Reference of the Modules","text":""},{"location":"module_1/#1-water_scan_mainpy","title":"\ud83d\udd39 1) <code>water_scan_main.py</code>","text":"<p>Main script that orchestrates the entire pipeline: - Initializes experiment in MLflow - Loads and processes the data - Creates a trainer using <code>TrainerFactory</code> - Optimizes hyperparameters with Optuna - Saves the model in MLflow - Registers the model in the Model Registry (production)</p> <p>\u2b05 Back to Home Page</p>"},{"location":"module_1/#src.water_scan_main.main","title":"<code>main()</code>","text":"<p>Executes the main pipeline for water potability classification.</p> <p>Steps: - Sets up the experiment in MLflow - Loads and preprocesses the data - Trains a Random Forest model using Optuna - Logs results with MLflow - Registers the trained model in the MLflow Registry</p> Source code in <code>src\\water_scan_main.py</code> <pre><code>def main():\n    \"\"\"\n    Executes the main pipeline for water potability classification.\n\n    Steps:\n    - Sets up the experiment in MLflow\n    - Loads and preprocesses the data\n    - Trains a Random Forest model using Optuna\n    - Logs results with MLflow\n    - Registers the trained model in the MLflow Registry\n    \"\"\"\n\n    # Set up experiment in MLflow\n    experiment_name = MLFlowLogger.setup_experiment(\n        'water_potability_classification_test'\n    )\n\n    print(f'main -&gt; experiment_name (base) = {experiment_name}')\n\n    # Load and preprocess the data\n    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n\n    data_path = os.path.join(base_dir, 'data', 'water_potability.csv')\n\n    data_pipeline = DataPipeline(data_path)\n\n    df = data_pipeline.load_and_clean_data()\n    preprocessor = DataPreprocessor(df, target='Potability')\n    X_train, X_test, y_train, y_test = preprocessor.split_data()\n    X_train, y_train = preprocessor.apply_smote(X_train, y_train)\n\n    # Create trainer via Factory (Random Forest)\n    trainer = TrainerFactory.create_trainer(\n        'random_forest', X_train, X_test, y_train, y_test\n    )\n    study_rf = trainer.run_optuna(n_trials=50)\n    best_model, rf_accuracy, signature = trainer.save_best_model(study_rf.best_params)\n    print('Accuracy:', rf_accuracy)\n    print(classification_report(y_test, best_model.predict(X_test)))\n\n    # Register the model in the MLflow Registry (Singleton)\n    registry_manager = ModelRegistryManager()\n    run_id = mlflow.search_runs(order_by=['start_time DESC']).iloc[0].run_id\n    model_uri = f'runs:/{run_id}/random_forest'\n    model_name = 'water_potability_rf'\n    registry_manager.register_and_transition(\n        model_uri=model_uri,\n        model_name=model_name,\n        description='Water potability classification model using Random Forest',\n    )\n</code></pre>"},{"location":"module_2/","title":"\ud83d\udcda Technical Reference of the Modules","text":""},{"location":"module_2/#2-data_pipelinepy","title":"\ud83d\udd39 2) <code>data_pipeline.py</code>","text":"<p>Contains two main classes:</p>"},{"location":"module_2/#datapipeline","title":"DataPipeline","text":"<p>Responsible for: - Loading the CSV dataset - Handling missing values</p>"},{"location":"module_2/#datapreprocessor","title":"DataPreprocessor","text":"<p>Responsible for: - Train/test split using <code>train_test_split</code> - Data balancing using SMOTE</p> <p>\u2b05 Back to Home Page</p>"},{"location":"module_2/#src.data_pipeline.DataPipeline","title":"<code>DataPipeline</code>","text":"<p>Class responsible for loading and cleaning raw data.</p> <p>Methods:</p> Name Description <code>- load_and_clean_data</code> <p>Reads a CSV file, handles missing values, and returns a cleaned DataFrame.</p> Source code in <code>src\\data_pipeline.py</code> <pre><code>class DataPipeline:\n    \"\"\"\n    Class responsible for loading and cleaning raw data.\n\n    Methods:\n        - load_and_clean_data: Reads a CSV file, handles missing values, and returns a cleaned DataFrame.\n    \"\"\"\n\n    def __init__(self, file_path: str):\n        \"\"\"\n        Initializes the class with the path to the CSV file.\n\n        Args:\n            file_path (str): Full path to the CSV dataset.\n        \"\"\"\n        self.file_path = file_path\n\n    def load_and_clean_data(self) -&gt; pd.DataFrame:\n        \"\"\"\n        Loads data from the CSV file, prints missing values before and after cleaning,\n        replaces missing values with the median of each column, and returns the cleaned DataFrame.\n\n        Returns:\n            pd.DataFrame: Cleaned DataFrame ready for preprocessing.\n        \"\"\"\n        df = pd.read_csv(self.file_path)\n        print('Missing values before treatment:\\n', df.isnull().sum())\n        df.fillna(df.median(), inplace=True)\n        print('Missing values after treatment:\\n', df.isnull().sum())\n        return df\n</code></pre>"},{"location":"module_2/#src.data_pipeline.DataPipeline.__init__","title":"<code>__init__(file_path)</code>","text":"<p>Initializes the class with the path to the CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Full path to the CSV dataset.</p> required Source code in <code>src\\data_pipeline.py</code> <pre><code>def __init__(self, file_path: str):\n    \"\"\"\n    Initializes the class with the path to the CSV file.\n\n    Args:\n        file_path (str): Full path to the CSV dataset.\n    \"\"\"\n    self.file_path = file_path\n</code></pre>"},{"location":"module_2/#src.data_pipeline.DataPipeline.load_and_clean_data","title":"<code>load_and_clean_data()</code>","text":"<p>Loads data from the CSV file, prints missing values before and after cleaning, replaces missing values with the median of each column, and returns the cleaned DataFrame.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Cleaned DataFrame ready for preprocessing.</p> Source code in <code>src\\data_pipeline.py</code> <pre><code>def load_and_clean_data(self) -&gt; pd.DataFrame:\n    \"\"\"\n    Loads data from the CSV file, prints missing values before and after cleaning,\n    replaces missing values with the median of each column, and returns the cleaned DataFrame.\n\n    Returns:\n        pd.DataFrame: Cleaned DataFrame ready for preprocessing.\n    \"\"\"\n    df = pd.read_csv(self.file_path)\n    print('Missing values before treatment:\\n', df.isnull().sum())\n    df.fillna(df.median(), inplace=True)\n    print('Missing values after treatment:\\n', df.isnull().sum())\n    return df\n</code></pre>"},{"location":"module_2/#src.data_pipeline.DataPreprocessor","title":"<code>DataPreprocessor</code>","text":"<p>Class responsible for preprocessing data for machine learning.</p> Main functions <ul> <li>split_data: Splits the dataset into training and testing sets.</li> <li>apply_smote: Applies the SMOTE oversampling technique to the training set.</li> </ul> Source code in <code>src\\data_pipeline.py</code> <pre><code>class DataPreprocessor:\n    \"\"\"\n    Class responsible for preprocessing data for machine learning.\n\n    Main functions:\n        - split_data: Splits the dataset into training and testing sets.\n        - apply_smote: Applies the SMOTE oversampling technique to the training set.\n    \"\"\"\n\n    def __init__(self, df: pd.DataFrame, target: str):\n        \"\"\"\n        Initializes the class with the DataFrame and the name of the target column.\n\n        Args:\n            df (pd.DataFrame): Cleaned dataset.\n            target (str): Name of the column representing the target variable (e.g., 'Potability').\n        \"\"\"\n        self.df = df\n        self.target = target\n\n    def split_data(self, test_size=0.2, random_state=42):\n        \"\"\"\n        Splits the data into training and testing sets while maintaining the target variable proportion.\n\n        Args:\n            test_size (float): Proportion of the dataset to include in the test split.\n            random_state (int): Seed for reproducibility.\n\n        Returns:\n            Tuple: X_train, X_test, y_train, y_test\n        \"\"\"\n        X = self.df.drop(columns=[self.target])\n        y = self.df[self.target]\n        return train_test_split(\n            X, y, test_size=test_size, stratify=y, random_state=random_state\n        )\n\n    def apply_smote(self, X_train, y_train):\n        \"\"\"\n        Applies the SMOTE oversampling technique to balance the classes in the training set.\n\n        Args:\n            X_train (DataFrame): Training set features.\n            y_train (Series): Training set target variable.\n\n        Returns:\n            Tuple: X_train_balanced, y_train_balanced\n        \"\"\"\n        over_sampler = SMOTE(random_state=42)\n        return over_sampler.fit_resample(X_train, y_train)\n</code></pre>"},{"location":"module_2/#src.data_pipeline.DataPreprocessor.__init__","title":"<code>__init__(df, target)</code>","text":"<p>Initializes the class with the DataFrame and the name of the target column.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Cleaned dataset.</p> required <code>target</code> <code>str</code> <p>Name of the column representing the target variable (e.g., 'Potability').</p> required Source code in <code>src\\data_pipeline.py</code> <pre><code>def __init__(self, df: pd.DataFrame, target: str):\n    \"\"\"\n    Initializes the class with the DataFrame and the name of the target column.\n\n    Args:\n        df (pd.DataFrame): Cleaned dataset.\n        target (str): Name of the column representing the target variable (e.g., 'Potability').\n    \"\"\"\n    self.df = df\n    self.target = target\n</code></pre>"},{"location":"module_2/#src.data_pipeline.DataPreprocessor.apply_smote","title":"<code>apply_smote(X_train, y_train)</code>","text":"<p>Applies the SMOTE oversampling technique to balance the classes in the training set.</p> <p>Parameters:</p> Name Type Description Default <code>X_train</code> <code>DataFrame</code> <p>Training set features.</p> required <code>y_train</code> <code>Series</code> <p>Training set target variable.</p> required <p>Returns:</p> Name Type Description <code>Tuple</code> <p>X_train_balanced, y_train_balanced</p> Source code in <code>src\\data_pipeline.py</code> <pre><code>def apply_smote(self, X_train, y_train):\n    \"\"\"\n    Applies the SMOTE oversampling technique to balance the classes in the training set.\n\n    Args:\n        X_train (DataFrame): Training set features.\n        y_train (Series): Training set target variable.\n\n    Returns:\n        Tuple: X_train_balanced, y_train_balanced\n    \"\"\"\n    over_sampler = SMOTE(random_state=42)\n    return over_sampler.fit_resample(X_train, y_train)\n</code></pre>"},{"location":"module_2/#src.data_pipeline.DataPreprocessor.split_data","title":"<code>split_data(test_size=0.2, random_state=42)</code>","text":"<p>Splits the data into training and testing sets while maintaining the target variable proportion.</p> <p>Parameters:</p> Name Type Description Default <code>test_size</code> <code>float</code> <p>Proportion of the dataset to include in the test split.</p> <code>0.2</code> <code>random_state</code> <code>int</code> <p>Seed for reproducibility.</p> <code>42</code> <p>Returns:</p> Name Type Description <code>Tuple</code> <p>X_train, X_test, y_train, y_test</p> Source code in <code>src\\data_pipeline.py</code> <pre><code>def split_data(self, test_size=0.2, random_state=42):\n    \"\"\"\n    Splits the data into training and testing sets while maintaining the target variable proportion.\n\n    Args:\n        test_size (float): Proportion of the dataset to include in the test split.\n        random_state (int): Seed for reproducibility.\n\n    Returns:\n        Tuple: X_train, X_test, y_train, y_test\n    \"\"\"\n    X = self.df.drop(columns=[self.target])\n    y = self.df[self.target]\n    return train_test_split(\n        X, y, test_size=test_size, stratify=y, random_state=random_state\n    )\n</code></pre>"},{"location":"module_3/","title":"\ud83d\udcda Technical Reference of the Modules","text":""},{"location":"module_3/#3-mlflow_loggerpy","title":"\ud83d\udd39 3) <code>mlflow_logger.py</code>","text":"<p>Facade that encapsulates logging functions for MLflow: - Experiment setup - Logging of artifacts:   - <code>classification_report</code>   - <code>confusion_matrix</code>   - <code>feature_importance</code></p> <p>\u2b05 Back to Home Page</p>"},{"location":"module_3/#src.mlflow_logger.MLFlowLogger","title":"<code>MLFlowLogger</code>","text":"<p>Facade for MLflow setup and logging.</p> <p>This class provides static methods to configure experiments, save artifacts, and log visualizations such as: - classification reports - confusion matrices - feature importance</p> Source code in <code>src\\mlflow_logger.py</code> <pre><code>class MLFlowLogger:\n    \"\"\"\n    Facade for MLflow setup and logging.\n\n    This class provides static methods to configure experiments,\n    save artifacts, and log visualizations such as:\n    - classification reports\n    - confusion matrices\n    - feature importance\n    \"\"\"\n\n    @staticmethod\n    def setup_experiment(experiment_name: str) -&gt; str:\n        \"\"\"\n        Creates a new MLflow experiment with the current timestamp and sets the tracking URI.\n\n        Args:\n            experiment_name (str): Base name of the experiment.\n\n        Returns:\n            str: Full experiment name with date and time.\n        \"\"\"\n        now = datetime.now()\n        current_time = now.strftime('%d/%m/%Y - %H:%M:%S')\n        mlflow.set_tracking_uri('http://localhost:5001/')\n        experiment_name_full = f'{experiment_name} ({current_time})'\n\n        print('___________________________________________________________')\n        print(f'Experiment name = {experiment_name_full}')\n        print('___________________________________________________________')\n\n        mlflow.set_experiment(experiment_name_full)\n        return experiment_name_full\n\n    @staticmethod\n    def log_artifacts_and_plots(trial_number, y_test, y_pred, X_train, model):\n        \"\"\"\n        Saves and logs the following artifacts to MLflow:\n        - Classification report\n        - Confusion matrix\n        - Feature importance plot\n\n        Args:\n            trial_number (int): Trial number during Optuna optimization.\n            y_test (array-like): True target values.\n            y_pred (array-like): Predicted values from the model.\n            X_train (DataFrame): Training set (used to extract feature names).\n            model (sklearn model): Trained model with `feature_importances_` attribute.\n        \"\"\"\n        # Classification Report\n        cls_report = classification_report(y_test, y_pred, output_dict=False)\n        report_path = f'classification_report_trial_{trial_number}.txt'\n        with open(report_path, 'w') as f:\n            f.write(cls_report)\n        mlflow.log_artifact(report_path)\n\n        # Confusion Matrix\n        cm = confusion_matrix(y_test, y_pred)\n        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n        disp.plot()\n        plt.title('Confusion Matrix')\n        plt.tight_layout()\n        cm_path = f'confusion_matrix_trial_{trial_number}.png'\n        plt.savefig(cm_path)\n        mlflow.log_artifact(cm_path)\n        plt.close()\n\n        # Feature Importance\n        importances = model.feature_importances_\n        plt.figure(figsize=(8, 5))\n        plt.barh(X_train.columns, importances)\n        plt.xlabel('Importance')\n        plt.title('Feature Importance')\n        plt.tight_layout()\n        fi_path = f'feature_importance_trial_{trial_number}.png'\n        plt.savefig(fi_path)\n        mlflow.log_artifact(fi_path)\n        plt.close()\n\n        # Limpeza dos arquivos locais\n        for path in [report_path, cm_path, fi_path]:\n            if os.path.exists(path):\n                os.remove(path)\n</code></pre>"},{"location":"module_3/#src.mlflow_logger.MLFlowLogger.log_artifacts_and_plots","title":"<code>log_artifacts_and_plots(trial_number, y_test, y_pred, X_train, model)</code>  <code>staticmethod</code>","text":"<p>Saves and logs the following artifacts to MLflow: - Classification report - Confusion matrix - Feature importance plot</p> <p>Parameters:</p> Name Type Description Default <code>trial_number</code> <code>int</code> <p>Trial number during Optuna optimization.</p> required <code>y_test</code> <code>array - like</code> <p>True target values.</p> required <code>y_pred</code> <code>array - like</code> <p>Predicted values from the model.</p> required <code>X_train</code> <code>DataFrame</code> <p>Training set (used to extract feature names).</p> required <code>model</code> <code>sklearn model</code> <p>Trained model with <code>feature_importances_</code> attribute.</p> required Source code in <code>src\\mlflow_logger.py</code> <pre><code>@staticmethod\ndef log_artifacts_and_plots(trial_number, y_test, y_pred, X_train, model):\n    \"\"\"\n    Saves and logs the following artifacts to MLflow:\n    - Classification report\n    - Confusion matrix\n    - Feature importance plot\n\n    Args:\n        trial_number (int): Trial number during Optuna optimization.\n        y_test (array-like): True target values.\n        y_pred (array-like): Predicted values from the model.\n        X_train (DataFrame): Training set (used to extract feature names).\n        model (sklearn model): Trained model with `feature_importances_` attribute.\n    \"\"\"\n    # Classification Report\n    cls_report = classification_report(y_test, y_pred, output_dict=False)\n    report_path = f'classification_report_trial_{trial_number}.txt'\n    with open(report_path, 'w') as f:\n        f.write(cls_report)\n    mlflow.log_artifact(report_path)\n\n    # Confusion Matrix\n    cm = confusion_matrix(y_test, y_pred)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n    disp.plot()\n    plt.title('Confusion Matrix')\n    plt.tight_layout()\n    cm_path = f'confusion_matrix_trial_{trial_number}.png'\n    plt.savefig(cm_path)\n    mlflow.log_artifact(cm_path)\n    plt.close()\n\n    # Feature Importance\n    importances = model.feature_importances_\n    plt.figure(figsize=(8, 5))\n    plt.barh(X_train.columns, importances)\n    plt.xlabel('Importance')\n    plt.title('Feature Importance')\n    plt.tight_layout()\n    fi_path = f'feature_importance_trial_{trial_number}.png'\n    plt.savefig(fi_path)\n    mlflow.log_artifact(fi_path)\n    plt.close()\n\n    # Limpeza dos arquivos locais\n    for path in [report_path, cm_path, fi_path]:\n        if os.path.exists(path):\n            os.remove(path)\n</code></pre>"},{"location":"module_3/#src.mlflow_logger.MLFlowLogger.setup_experiment","title":"<code>setup_experiment(experiment_name)</code>  <code>staticmethod</code>","text":"<p>Creates a new MLflow experiment with the current timestamp and sets the tracking URI.</p> <p>Parameters:</p> Name Type Description Default <code>experiment_name</code> <code>str</code> <p>Base name of the experiment.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Full experiment name with date and time.</p> Source code in <code>src\\mlflow_logger.py</code> <pre><code>@staticmethod\ndef setup_experiment(experiment_name: str) -&gt; str:\n    \"\"\"\n    Creates a new MLflow experiment with the current timestamp and sets the tracking URI.\n\n    Args:\n        experiment_name (str): Base name of the experiment.\n\n    Returns:\n        str: Full experiment name with date and time.\n    \"\"\"\n    now = datetime.now()\n    current_time = now.strftime('%d/%m/%Y - %H:%M:%S')\n    mlflow.set_tracking_uri('http://localhost:5001/')\n    experiment_name_full = f'{experiment_name} ({current_time})'\n\n    print('___________________________________________________________')\n    print(f'Experiment name = {experiment_name_full}')\n    print('___________________________________________________________')\n\n    mlflow.set_experiment(experiment_name_full)\n    return experiment_name_full\n</code></pre>"},{"location":"module_4/","title":"\ud83d\udcda Technical Reference of the Modules","text":""},{"location":"module_4/#4-model_registrypy","title":"\ud83d\udd39 4) <code>model_registry.py</code>","text":"<p>Uses the Singleton pattern to register models in the MLflow Registry: - Register the model URI - Add a description and transition the model to production - Archive previous versions</p>"},{"location":"module_4/#src.model_registry.ModelRegistryManager","title":"<code>ModelRegistryManager</code>","text":"<p>Class responsible for registering and managing model versions in the MLflow Registry.</p> <p>Uses the Singleton metaclass to ensure that only one instance of the MLflowClient connection is used throughout the pipeline execution.</p> Source code in <code>src\\model_registry.py</code> <pre><code>class ModelRegistryManager(metaclass=Singleton):\n    \"\"\"\n    Class responsible for registering and managing model versions in the MLflow Registry.\n\n    Uses the Singleton metaclass to ensure that only one instance\n    of the MLflowClient connection is used throughout the pipeline execution.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes the client for communication with the MLflow Tracking Server.\n        \"\"\"\n        self.client = MlflowClient()\n\n    def register_and_transition(\n        self,\n        model_uri: str,\n        model_name: str,\n        description: str,\n        transition_stage='Production',\n    ):\n        \"\"\"\n        Registers the trained model in the MLflow Registry and transitions it to a specified stage.\n\n        Args:\n            model_uri (str): URI of the saved model (e.g., \"runs:/&lt;run_id&gt;/model_name\").\n            model_name (str): Unique name for the model in the registry.\n            description (str): Description of the model (used in both the version and name).\n            transition_stage (str, optional): Stage to transition to. Default: \"Production\".\n\n        Returns:\n            model_details: Object containing information about the registered version.\n        \"\"\"\n        model_details = mlflow.register_model(model_uri=model_uri, name=model_name)\n        self.client.update_registered_model(name=model_name, description=description)\n        self.client.update_model_version(\n            name=model_name,\n            version=model_details.version,\n            description='Optimized version via Optuna with SMOTE',\n        )\n        self.client.transition_model_version_stage(\n            name=model_name,\n            version=model_details.version,\n            stage=transition_stage,\n            archive_existing_versions=True,\n        )\n        print(\n            f\"\u2705 Model '{model_name}' (version {model_details.version}) promoted to '{transition_stage}'.\"\n        )\n        return model_details\n</code></pre>"},{"location":"module_4/#src.model_registry.ModelRegistryManager.__init__","title":"<code>__init__()</code>","text":"<p>Initializes the client for communication with the MLflow Tracking Server.</p> Source code in <code>src\\model_registry.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Initializes the client for communication with the MLflow Tracking Server.\n    \"\"\"\n    self.client = MlflowClient()\n</code></pre>"},{"location":"module_4/#src.model_registry.ModelRegistryManager.register_and_transition","title":"<code>register_and_transition(model_uri, model_name, description, transition_stage='Production')</code>","text":"<p>Registers the trained model in the MLflow Registry and transitions it to a specified stage.</p> <p>Parameters:</p> Name Type Description Default <code>model_uri</code> <code>str</code> <p>URI of the saved model (e.g., \"runs://model_name\"). required <code>model_name</code> <code>str</code> <p>Unique name for the model in the registry.</p> required <code>description</code> <code>str</code> <p>Description of the model (used in both the version and name).</p> required <code>transition_stage</code> <code>str</code> <p>Stage to transition to. Default: \"Production\".</p> <code>'Production'</code> <p>Returns:</p> Name Type Description <code>model_details</code> <p>Object containing information about the registered version.</p> Source code in <code>src\\model_registry.py</code> <pre><code>def register_and_transition(\n    self,\n    model_uri: str,\n    model_name: str,\n    description: str,\n    transition_stage='Production',\n):\n    \"\"\"\n    Registers the trained model in the MLflow Registry and transitions it to a specified stage.\n\n    Args:\n        model_uri (str): URI of the saved model (e.g., \"runs:/&lt;run_id&gt;/model_name\").\n        model_name (str): Unique name for the model in the registry.\n        description (str): Description of the model (used in both the version and name).\n        transition_stage (str, optional): Stage to transition to. Default: \"Production\".\n\n    Returns:\n        model_details: Object containing information about the registered version.\n    \"\"\"\n    model_details = mlflow.register_model(model_uri=model_uri, name=model_name)\n    self.client.update_registered_model(name=model_name, description=description)\n    self.client.update_model_version(\n        name=model_name,\n        version=model_details.version,\n        description='Optimized version via Optuna with SMOTE',\n    )\n    self.client.transition_model_version_stage(\n        name=model_name,\n        version=model_details.version,\n        stage=transition_stage,\n        archive_existing_versions=True,\n    )\n    print(\n        f\"\u2705 Model '{model_name}' (version {model_details.version}) promoted to '{transition_stage}'.\"\n    )\n    return model_details\n</code></pre> <p>\u2b05 Back to Home Page</p>"},{"location":"module_4/#src.model_registry.Singleton","title":"<code>Singleton</code>","text":"<p>               Bases: <code>type</code></p> <p>Metaclass for implementing the Singleton pattern.</p> <p>Ensures that only one instance of the class is created and shared throughout the application's lifecycle.</p> Source code in <code>src\\model_registry.py</code> <pre><code>class Singleton(type):\n    \"\"\"\n    Metaclass for implementing the Singleton pattern.\n\n    Ensures that only one instance of the class is created and shared\n    throughout the application's lifecycle.\n    \"\"\"\n\n    _instances = {}\n\n    def __call__(cls, *args, **kwargs):\n        \"\"\"\n        Checks if an instance already exists.\n        If not, creates a new one and stores it in the _instances dictionary.\n\n        Returns:\n            The unique instance of the class.\n        \"\"\"\n        if cls not in cls._instances:\n            cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs)\n        return cls._instances[cls]\n</code></pre>"},{"location":"module_4/#src.model_registry.Singleton.__call__","title":"<code>__call__(*args, **kwargs)</code>","text":"<p>Checks if an instance already exists. If not, creates a new one and stores it in the _instances dictionary.</p> <p>Returns:</p> Type Description <p>The unique instance of the class.</p> Source code in <code>src\\model_registry.py</code> <pre><code>def __call__(cls, *args, **kwargs):\n    \"\"\"\n    Checks if an instance already exists.\n    If not, creates a new one and stores it in the _instances dictionary.\n\n    Returns:\n        The unique instance of the class.\n    \"\"\"\n    if cls not in cls._instances:\n        cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs)\n    return cls._instances[cls]\n</code></pre>"},{"location":"module_5/","title":"\ud83d\udcda Technical Reference of the Modules","text":""},{"location":"module_5/#5-model_trainerpy","title":"\ud83d\udd39 5) <code>model_trainer.py</code>","text":"<p>Main class: <code>RandomForestTrainer</code></p> <p>Functions: - Optimizes hyperparameters with Optuna  - Logs to MLflow (params, metrics, model)  - Logs artifacts (report, matrix, feature importance)  - Saves the best model with complete logging</p> <p>\u2b05 Back to Home Page</p>"},{"location":"module_5/#src.model_trainer.RandomForestTrainer","title":"<code>RandomForestTrainer</code>","text":"<p>Class responsible for training and evaluating a RandomForestClassifier model, including hyperparameter optimization with Optuna and logging with MLflow.</p> Source code in <code>src\\model_trainer.py</code> <pre><code>class RandomForestTrainer:\n    \"\"\"\n    Class responsible for training and evaluating a RandomForestClassifier model,\n    including hyperparameter optimization with Optuna and logging with MLflow.\n    \"\"\"\n\n    def __init__(self, X_train, X_test, y_train, y_test):\n        \"\"\"\n        Initializes the trainer with training and testing datasets.\n\n        Args:\n            X_train (DataFrame): Training set - features.\n            X_test (DataFrame): Test set - features.\n            y_train (Series): Training set - target.\n            y_test (Series): Test set - target.\n        \"\"\"\n        self.X_train = X_train\n        self.X_test = X_test\n        self.y_train = y_train\n        self.y_test = y_test\n\n    def objective(self, trial):\n        \"\"\"\n        Objective function used by Optuna to test combinations of hyperparameters.\n\n        Args:\n            trial (optuna.trial): Optuna trial object.\n\n        Returns:\n            float: Model accuracy with the tested hyperparameters.\n        \"\"\"\n        params = {\n            'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n            'max_depth': trial.suggest_categorical('max_depth', [10, 20, None]),\n            'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n            'random_state': 42,\n        }\n\n        model = RandomForestClassifier(**params)\n        model.fit(self.X_train, self.y_train)\n        y_pred = model.predict(self.X_test)\n\n        acc = accuracy_score(self.y_test, y_pred)\n        precision = precision_score(self.y_test, y_pred, zero_division=0)\n        recall = recall_score(self.y_test, y_pred, zero_division=0)\n        f1 = f1_score(self.y_test, y_pred, zero_division=0)\n        bal_acc = balanced_accuracy_score(self.y_test, y_pred)\n        try:\n            roc_auc = roc_auc_score(self.y_test, model.predict_proba(self.X_test)[:, 1])\n        except Exception:\n            roc_auc = np.nan\n\n        metrics = {\n            'accuracy': acc,\n            'precision': precision,\n            'recall': recall,\n            'f1_score': f1,\n            'balanced_accuracy': bal_acc,\n            'roc_auc': roc_auc,\n        }\n\n        try:\n            if mlflow.active_run():\n                mlflow.end_run()\n            with mlflow.start_run(run_name=f'RF_Optuna_Trial_{trial.number}'):\n                mlflow.set_tag('optuna_trial_number', trial.number)\n                mlflow.log_params(params)\n                mlflow.log_metrics(metrics)\n\n                input_example = self.X_train.iloc[:1]\n                signature = infer_signature(self.X_train, model.predict(self.X_train))\n                mlflow.sklearn.log_model(\n                    sk_model=model,\n                    artifact_path='random_forest',\n                    input_example=input_example,\n                    signature=signature,\n                )\n\n                MLFlowLogger.log_artifacts_and_plots(\n                    trial.number, self.y_test, y_pred, self.X_train, model\n                )\n        except Exception as e:\n            print(f'[Erro no MLflow - trial {trial.number}] {e}')\n        finally:\n            if mlflow.active_run():\n                mlflow.end_run()\n\n        return acc\n\n    def run_optuna(self, n_trials=10):\n        \"\"\"\n        Runs the hyperparameter optimization process using Optuna.\n\n        Args:\n            n_trials (int): Number of optimization trials.\n\n        Returns:\n            optuna.Study: Study containing the results of the trials.\n        \"\"\"\n        study = optuna.create_study(direction='maximize')\n        study.optimize(partial(self.objective), n_trials=n_trials)\n        print('Melhores par\u00e2metros:', study.best_params)\n        return study\n\n    def save_best_model(self, best_params):\n        \"\"\"\n        Trains the final model using the best hyperparameters found,\n        logs metrics and artifacts to MLflow, and returns the final model.\n\n        Args:\n            best_params (dict): Dictionary containing the best hyperparameters.\n\n        Returns:\n            Tuple[sklearn model, float, mlflow.models.signature]: Model, final accuracy, and model signature.\n        \"\"\"\n        model = RandomForestClassifier(**best_params, random_state=42)\n        model.fit(self.X_train, self.y_train)\n        y_pred = model.predict(self.X_test)\n\n        acc = accuracy_score(self.y_test, y_pred)\n        precision = precision_score(self.y_test, y_pred, zero_division=0)\n        recall = recall_score(self.y_test, y_pred, zero_division=0)\n        f1 = f1_score(self.y_test, y_pred, zero_division=0)\n        bal_acc = balanced_accuracy_score(self.y_test, y_pred)\n        try:\n            roc_auc = roc_auc_score(self.y_test, model.predict_proba(self.X_test)[:, 1])\n        except Exception:\n            roc_auc = np.nan\n\n        metrics = {\n            'final_accuracy': acc,\n            'precision': precision,\n            'recall': recall,\n            'f1_score': f1,\n            'balanced_accuracy': bal_acc,\n            'roc_auc': roc_auc,\n        }\n\n        input_example = self.X_train.iloc[:1]\n        signature = infer_signature(self.X_train, model.predict(self.X_train))\n\n        try:\n            if mlflow.active_run():\n                mlflow.end_run()\n            with mlflow.start_run(run_name='BestModel_Final'):\n                mlflow.set_tag('model_version', 'final')\n                mlflow.log_params(best_params)\n                mlflow.log_metrics(metrics)\n                mlflow.sklearn.log_model(\n                    sk_model=model,\n                    artifact_path='random_forest',\n                    input_example=input_example,\n                    signature=signature,\n                )\n\n                cls_report = classification_report(\n                    self.y_test, y_pred, output_dict=False\n                )\n                report_file = 'classification_report.txt'\n                with open(report_file, 'w') as f:\n                    f.write(cls_report)\n                mlflow.log_artifact(report_file)\n\n                from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n\n                cm = confusion_matrix(self.y_test, y_pred)\n                disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n                disp.plot()\n                plt.title('Confusion Matrix')\n                plt.tight_layout()\n                cm_file = 'confusion_matrix.png'\n                plt.savefig(cm_file)\n                mlflow.log_artifact(cm_file)\n                plt.close()\n\n                importances = model.feature_importances_\n                plt.figure(figsize=(8, 5))\n                plt.barh(self.X_train.columns, importances)\n                plt.xlabel('Importance')\n                plt.title('Feature Importance')\n                plt.tight_layout()\n                fi_file = 'feature_importance.png'\n                plt.savefig(fi_file)\n                mlflow.log_artifact(fi_file)\n                plt.close()\n        except Exception as e:\n            print(f'[Erro ao salvar modelo final] {e}')\n        finally:\n            if mlflow.active_run():\n                mlflow.end_run()\n\n        for file in [\n            'classification_report.txt',\n            'confusion_matrix.png',\n            'feature_importance.png',\n        ]:\n            if os.path.exists(file):\n                os.remove(file)\n        return model, acc, signature\n</code></pre>"},{"location":"module_5/#src.model_trainer.RandomForestTrainer.__init__","title":"<code>__init__(X_train, X_test, y_train, y_test)</code>","text":"<p>Initializes the trainer with training and testing datasets.</p> <p>Parameters:</p> Name Type Description Default <code>X_train</code> <code>DataFrame</code> <p>Training set - features.</p> required <code>X_test</code> <code>DataFrame</code> <p>Test set - features.</p> required <code>y_train</code> <code>Series</code> <p>Training set - target.</p> required <code>y_test</code> <code>Series</code> <p>Test set - target.</p> required Source code in <code>src\\model_trainer.py</code> <pre><code>def __init__(self, X_train, X_test, y_train, y_test):\n    \"\"\"\n    Initializes the trainer with training and testing datasets.\n\n    Args:\n        X_train (DataFrame): Training set - features.\n        X_test (DataFrame): Test set - features.\n        y_train (Series): Training set - target.\n        y_test (Series): Test set - target.\n    \"\"\"\n    self.X_train = X_train\n    self.X_test = X_test\n    self.y_train = y_train\n    self.y_test = y_test\n</code></pre>"},{"location":"module_5/#src.model_trainer.RandomForestTrainer.objective","title":"<code>objective(trial)</code>","text":"<p>Objective function used by Optuna to test combinations of hyperparameters.</p> <p>Parameters:</p> Name Type Description Default <code>trial</code> <code>trial</code> <p>Optuna trial object.</p> required <p>Returns:</p> Name Type Description <code>float</code> <p>Model accuracy with the tested hyperparameters.</p> Source code in <code>src\\model_trainer.py</code> <pre><code>def objective(self, trial):\n    \"\"\"\n    Objective function used by Optuna to test combinations of hyperparameters.\n\n    Args:\n        trial (optuna.trial): Optuna trial object.\n\n    Returns:\n        float: Model accuracy with the tested hyperparameters.\n    \"\"\"\n    params = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n        'max_depth': trial.suggest_categorical('max_depth', [10, 20, None]),\n        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n        'random_state': 42,\n    }\n\n    model = RandomForestClassifier(**params)\n    model.fit(self.X_train, self.y_train)\n    y_pred = model.predict(self.X_test)\n\n    acc = accuracy_score(self.y_test, y_pred)\n    precision = precision_score(self.y_test, y_pred, zero_division=0)\n    recall = recall_score(self.y_test, y_pred, zero_division=0)\n    f1 = f1_score(self.y_test, y_pred, zero_division=0)\n    bal_acc = balanced_accuracy_score(self.y_test, y_pred)\n    try:\n        roc_auc = roc_auc_score(self.y_test, model.predict_proba(self.X_test)[:, 1])\n    except Exception:\n        roc_auc = np.nan\n\n    metrics = {\n        'accuracy': acc,\n        'precision': precision,\n        'recall': recall,\n        'f1_score': f1,\n        'balanced_accuracy': bal_acc,\n        'roc_auc': roc_auc,\n    }\n\n    try:\n        if mlflow.active_run():\n            mlflow.end_run()\n        with mlflow.start_run(run_name=f'RF_Optuna_Trial_{trial.number}'):\n            mlflow.set_tag('optuna_trial_number', trial.number)\n            mlflow.log_params(params)\n            mlflow.log_metrics(metrics)\n\n            input_example = self.X_train.iloc[:1]\n            signature = infer_signature(self.X_train, model.predict(self.X_train))\n            mlflow.sklearn.log_model(\n                sk_model=model,\n                artifact_path='random_forest',\n                input_example=input_example,\n                signature=signature,\n            )\n\n            MLFlowLogger.log_artifacts_and_plots(\n                trial.number, self.y_test, y_pred, self.X_train, model\n            )\n    except Exception as e:\n        print(f'[Erro no MLflow - trial {trial.number}] {e}')\n    finally:\n        if mlflow.active_run():\n            mlflow.end_run()\n\n    return acc\n</code></pre>"},{"location":"module_5/#src.model_trainer.RandomForestTrainer.run_optuna","title":"<code>run_optuna(n_trials=10)</code>","text":"<p>Runs the hyperparameter optimization process using Optuna.</p> <p>Parameters:</p> Name Type Description Default <code>n_trials</code> <code>int</code> <p>Number of optimization trials.</p> <code>10</code> <p>Returns:</p> Type Description <p>optuna.Study: Study containing the results of the trials.</p> Source code in <code>src\\model_trainer.py</code> <pre><code>def run_optuna(self, n_trials=10):\n    \"\"\"\n    Runs the hyperparameter optimization process using Optuna.\n\n    Args:\n        n_trials (int): Number of optimization trials.\n\n    Returns:\n        optuna.Study: Study containing the results of the trials.\n    \"\"\"\n    study = optuna.create_study(direction='maximize')\n    study.optimize(partial(self.objective), n_trials=n_trials)\n    print('Melhores par\u00e2metros:', study.best_params)\n    return study\n</code></pre>"},{"location":"module_5/#src.model_trainer.RandomForestTrainer.save_best_model","title":"<code>save_best_model(best_params)</code>","text":"<p>Trains the final model using the best hyperparameters found, logs metrics and artifacts to MLflow, and returns the final model.</p> <p>Parameters:</p> Name Type Description Default <code>best_params</code> <code>dict</code> <p>Dictionary containing the best hyperparameters.</p> required <p>Returns:</p> Type Description <p>Tuple[sklearn model, float, mlflow.models.signature]: Model, final accuracy, and model signature.</p> Source code in <code>src\\model_trainer.py</code> <pre><code>def save_best_model(self, best_params):\n    \"\"\"\n    Trains the final model using the best hyperparameters found,\n    logs metrics and artifacts to MLflow, and returns the final model.\n\n    Args:\n        best_params (dict): Dictionary containing the best hyperparameters.\n\n    Returns:\n        Tuple[sklearn model, float, mlflow.models.signature]: Model, final accuracy, and model signature.\n    \"\"\"\n    model = RandomForestClassifier(**best_params, random_state=42)\n    model.fit(self.X_train, self.y_train)\n    y_pred = model.predict(self.X_test)\n\n    acc = accuracy_score(self.y_test, y_pred)\n    precision = precision_score(self.y_test, y_pred, zero_division=0)\n    recall = recall_score(self.y_test, y_pred, zero_division=0)\n    f1 = f1_score(self.y_test, y_pred, zero_division=0)\n    bal_acc = balanced_accuracy_score(self.y_test, y_pred)\n    try:\n        roc_auc = roc_auc_score(self.y_test, model.predict_proba(self.X_test)[:, 1])\n    except Exception:\n        roc_auc = np.nan\n\n    metrics = {\n        'final_accuracy': acc,\n        'precision': precision,\n        'recall': recall,\n        'f1_score': f1,\n        'balanced_accuracy': bal_acc,\n        'roc_auc': roc_auc,\n    }\n\n    input_example = self.X_train.iloc[:1]\n    signature = infer_signature(self.X_train, model.predict(self.X_train))\n\n    try:\n        if mlflow.active_run():\n            mlflow.end_run()\n        with mlflow.start_run(run_name='BestModel_Final'):\n            mlflow.set_tag('model_version', 'final')\n            mlflow.log_params(best_params)\n            mlflow.log_metrics(metrics)\n            mlflow.sklearn.log_model(\n                sk_model=model,\n                artifact_path='random_forest',\n                input_example=input_example,\n                signature=signature,\n            )\n\n            cls_report = classification_report(\n                self.y_test, y_pred, output_dict=False\n            )\n            report_file = 'classification_report.txt'\n            with open(report_file, 'w') as f:\n                f.write(cls_report)\n            mlflow.log_artifact(report_file)\n\n            from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n\n            cm = confusion_matrix(self.y_test, y_pred)\n            disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n            disp.plot()\n            plt.title('Confusion Matrix')\n            plt.tight_layout()\n            cm_file = 'confusion_matrix.png'\n            plt.savefig(cm_file)\n            mlflow.log_artifact(cm_file)\n            plt.close()\n\n            importances = model.feature_importances_\n            plt.figure(figsize=(8, 5))\n            plt.barh(self.X_train.columns, importances)\n            plt.xlabel('Importance')\n            plt.title('Feature Importance')\n            plt.tight_layout()\n            fi_file = 'feature_importance.png'\n            plt.savefig(fi_file)\n            mlflow.log_artifact(fi_file)\n            plt.close()\n    except Exception as e:\n        print(f'[Erro ao salvar modelo final] {e}')\n    finally:\n        if mlflow.active_run():\n            mlflow.end_run()\n\n    for file in [\n        'classification_report.txt',\n        'confusion_matrix.png',\n        'feature_importance.png',\n    ]:\n        if os.path.exists(file):\n            os.remove(file)\n    return model, acc, signature\n</code></pre>"},{"location":"module_6/","title":"\ud83d\udcda Technical Reference of the Modules","text":""},{"location":"module_6/#6-trainer_factorypy","title":"\ud83d\udd39 6) <code>trainer_factory.py</code>","text":"<p>Implements the Factory pattern to instantiate trainers. Currently implemented: - <code>\"random_forest\"</code>: returns an instance of <code>RandomForestTrainer</code></p> <p>\u2b05 Back to Home Page</p>"},{"location":"module_6/#src.trainer_factory.TrainerFactory","title":"<code>TrainerFactory</code>","text":"<p>Trainer factory that instantiates the appropriate model based on the requested type.</p> <p>Currently supports only Random Forest, but can be extended to include other types such as XGBoost, LightGBM, etc.</p> Source code in <code>src\\trainer_factory.py</code> <pre><code>class TrainerFactory:\n    \"\"\"\n    Trainer factory that instantiates the appropriate model\n    based on the requested type.\n\n    Currently supports only Random Forest, but can be extended\n    to include other types such as XGBoost, LightGBM, etc.\n    \"\"\"\n\n    @staticmethod\n    def create_trainer(model_type: str, X_train, X_test, y_train, y_test):\n        \"\"\"\n        Creates and returns an instance of the trainer corresponding to the specified model type.\n\n        Args:\n            model_type (str): Name of the desired model (e.g., \"random_forest\").\n            X_train (DataFrame): Training features.\n            X_test (DataFrame): Testing features.\n            y_train (Series): Training target.\n            y_test (Series): Testing target.\n\n        Returns:\n            A trainer object with training and saving interface.\n\n        Raises:\n            ValueError: If the model type is not supported.\n        \"\"\"\n        if model_type.lower() == 'random_forest':\n            return RandomForestTrainer(X_train, X_test, y_train, y_test)\n        # Other trainers can be added here (e.g., XGBoostTrainer, LGBMTrainer, etc.)\n        raise ValueError(f\"Modelo do tipo '{model_type}' n\u00e3o suportado.\")\n</code></pre>"},{"location":"module_6/#src.trainer_factory.TrainerFactory.create_trainer","title":"<code>create_trainer(model_type, X_train, X_test, y_train, y_test)</code>  <code>staticmethod</code>","text":"<p>Creates and returns an instance of the trainer corresponding to the specified model type.</p> <p>Parameters:</p> Name Type Description Default <code>model_type</code> <code>str</code> <p>Name of the desired model (e.g., \"random_forest\").</p> required <code>X_train</code> <code>DataFrame</code> <p>Training features.</p> required <code>X_test</code> <code>DataFrame</code> <p>Testing features.</p> required <code>y_train</code> <code>Series</code> <p>Training target.</p> required <code>y_test</code> <code>Series</code> <p>Testing target.</p> required <p>Returns:</p> Type Description <p>A trainer object with training and saving interface.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the model type is not supported.</p> Source code in <code>src\\trainer_factory.py</code> <pre><code>@staticmethod\ndef create_trainer(model_type: str, X_train, X_test, y_train, y_test):\n    \"\"\"\n    Creates and returns an instance of the trainer corresponding to the specified model type.\n\n    Args:\n        model_type (str): Name of the desired model (e.g., \"random_forest\").\n        X_train (DataFrame): Training features.\n        X_test (DataFrame): Testing features.\n        y_train (Series): Training target.\n        y_test (Series): Testing target.\n\n    Returns:\n        A trainer object with training and saving interface.\n\n    Raises:\n        ValueError: If the model type is not supported.\n    \"\"\"\n    if model_type.lower() == 'random_forest':\n        return RandomForestTrainer(X_train, X_test, y_train, y_test)\n    # Other trainers can be added here (e.g., XGBoostTrainer, LGBMTrainer, etc.)\n    raise ValueError(f\"Modelo do tipo '{model_type}' n\u00e3o suportado.\")\n</code></pre>"},{"location":"modules_index/","title":"\ud83d\udcda Technical Reference of the Modules","text":""},{"location":"modules_index/#water_scan_mainpy","title":"\ud83d\udd39 water_scan_main.py","text":"<p>Main script that orchestrates the entire pipeline: - Initializes an experiment in MLflow - Loads and processes the data - Creates a trainer via <code>TrainerFactory</code> - Optimizes hyperparameters using Optuna - Saves the model in MLflow - Registers the model in the Model Registry (production)</p>"},{"location":"modules_index/#data_pipelinepy","title":"\ud83d\udd39 data_pipeline.py","text":"<p>Contains two main classes:</p>"},{"location":"modules_index/#datapipeline","title":"DataPipeline","text":"<p>Responsible for: - Loading the CSV dataset - Handling missing values</p>"},{"location":"modules_index/#datapreprocessor","title":"DataPreprocessor","text":"<p>Responsible for: - Train/test split using <code>train_test_split</code> - Data balancing using SMOTE</p>"},{"location":"modules_index/#mlflow_loggerpy","title":"\ud83d\udd39 mlflow_logger.py","text":"<p>Facade that encapsulates logging functions in MLflow: - Experiment setup - Artifact logging:   - <code>classification_report</code>   - <code>confusion_matrix</code>   - <code>feature_importance</code></p>"},{"location":"modules_index/#model_registrypy","title":"\ud83d\udd39 model_registry.py","text":"<p>Uses the Singleton pattern to register models in the MLflow Registry: - Register the model URI - Add a description and transition to production - Archive previous versions</p>"},{"location":"modules_index/#model_trainerpy","title":"\ud83d\udd39 model_trainer.py","text":"<p>Main class: <code>RandomForestTrainer</code></p> <p>Functions: - Optimizes hyperparameters with Optuna - Logs to MLflow (params, metrics, model) - Logs artifacts (report, matrix, importance) - Saves the best model with complete logging</p>"},{"location":"modules_index/#trainer_factorypy","title":"\ud83d\udd39 trainer_factory.py","text":"<p>Implements the Factory pattern to instantiate trainers. Currently implemented: - <code>\"random_forest\"</code>: returns an instance of <code>RandomForestTrainer</code></p> <p>\u2b05 Back to Home Page</p>"},{"location":"project_structure/","title":"Project Structure","text":"<pre>\ud83d\udcc2 WATER_SCAN_AI                                       \u2705 (Project root directory)</pre> <pre>\u251c\u2500\u2500 \ud83d\udcc2 .github/workflows                               \u2705 (CI/CD workflows with GitHub Actions)</pre> <pre>\u2502    \u251c\u2500\u2500 quality-check.yml                             \ud83d\udccc (Code quality check pipeline)</pre> <pre>\u251c\u2500\u2500 \ud83d\udcc2 data                                            \u2705 (Data used or generated by the project)</pre> <pre>\u2502    \u251c\u2500\u2500 water_potability.csv                          \ud83d\udccc (Input dataset)</pre> <pre>\u251c\u2500\u2500 \ud83d\udcc2 docs                                            \u2705 (Project documentation generated with MkDocs)</pre> <pre>\u2502    \u251c\u2500\u2500 \ud83d\udcc2 assets/images                              \ud83d\udccc (Technical documentation images)</pre> <pre>\u2502    \u2502    \u251c\u2500\u2500 \ud83d\udcc2 crisp_dm                              \ud83d\udccc (Images from CRISP-DM stages)</pre> <pre>\u2502    \u2502    \u2502    \u251c\u2500\u2500 2.2.1 - Dataset overview.png</pre> <pre>\u2502    \u2502    \u2502    \u251c\u2500\u2500 2.2.2 - Checking types and missing values.png</pre> <pre>\u2502    \u2502    \u2502    \u251c\u2500\u2500 2.2.3 - Missing values visualization.png</pre> <pre>\u2502    \u2502    \u2502    \u251c\u2500\u2500 2.2.4 - Descriptive statistics.png</pre> <pre>\u2502    \u2502    \u2502    \u251c\u2500\u2500 2.2.5 - Target variable distribution.png</pre> <pre>\u2502    \u2502    \u2502    \u251c\u2500\u2500 2.2.6 - Target class percentage.png</pre> <pre>\u2502    \u2502    \u2502    \u251c\u2500\u2500 2.2.7 - Histograms of variable distributions.png</pre> <pre>\u2502    \u2502    \u2502    \u251c\u2500\u2500 2.2.8 - Boxplots to detect outliers.png</pre> <pre>\u2502    \u2502    \u2502    \u251c\u2500\u2500 2.2.9 - Variable correlation heatmap.png</pre> <pre>\u2502    \u2502    \u2502    \u251c\u2500\u2500 2.2.10 - KDE plots by class.png</pre> <pre>\u2502    \u2502    \u2502    \u251c\u2500\u2500 5.1 - Model evaluation.png</pre> <pre>\u2502    \u2502    \u2502    \u251c\u2500\u2500 crisp_dm_introduction.png</pre> <pre>\u2502    \u2502    \u251c\u2500\u2500 minio_configuration_access.png</pre> <pre>\u2502    \u2502    \u251c\u2500\u2500 minio_configuration_buckets_part_1.png</pre> <pre>\u2502    \u2502    \u251c\u2500\u2500 minio_configuration_buckets_part_2.png</pre> <pre>\u2502    \u251c\u2500\u2500 \ud83d\udcc4 changelog.md                               \ud83d\udccc (Change log)</pre> <pre>\u2502    \u251c\u2500\u2500 \ud83d\udcc4 contributing.md                            \ud83d\udccc (Contribution guide)</pre> <pre>\u2502    \u251c\u2500\u2500 \ud83d\udcc4 index.md                                   \ud83d\udccc (Main documentation page)</pre> <pre>\u2502    \u251c\u2500\u2500 \ud83d\udcc4 crisp_dm_stages.md                         \ud83d\udccc (Project methodology using CRISP-DM)</pre> <pre>\u2502    \u251c\u2500\u2500 \ud83d\udcc4 installation.md                            \ud83d\udccc (Installation guide)</pre> <pre>\u2502    \u251c\u2500\u2500 \ud83d\udcc4 usage.md                                   \ud83d\udccc (How to use the project)</pre> <pre>\u2502    \u251c\u2500\u2500 \ud83d\udcc4 project_structure.md                       \ud83d\udccc (Project structure)</pre> <pre>\u2502    \u251c\u2500\u2500 \ud83d\udcc4 modules_index.md                           \ud83d\udccc (Modules index)</pre> <pre>\u2502    \u251c\u2500\u2500 \ud83d\udcc4 module_1.md                                \ud83d\udccc (Module 1: water_scan_main.py)</pre> <pre>\u2502    \u251c\u2500\u2500 \ud83d\udcc4 module_2.md                                \ud83d\udccc (Module 2: data_pipeline.py)</pre> <pre>\u2502    \u251c\u2500\u2500 \ud83d\udcc4 module_3.md                                \ud83d\udccc (Module 3: mlflow_logger.py)</pre> <pre>\u2502    \u251c\u2500\u2500 \ud83d\udcc4 module_4.md                                \ud83d\udccc (Module 4: model_registry.py)</pre> <pre>\u2502    \u251c\u2500\u2500 \ud83d\udcc4 module_5.md                                \ud83d\udccc (Module 5: model_trainer.py)</pre> <pre>\u2502    \u251c\u2500\u2500 \ud83d\udcc4 module_6.md                                \ud83d\udccc (Module 6: trainer_factory.py)</pre> <pre>\u251c\u2500\u2500 \ud83d\udcc2 mlflow-minio-setup                              \u2705 (MLflow + MinIO setup scripts and configs)</pre> <pre>\u2502    \u251c\u2500\u2500 docker-compose.yml                            \ud83d\udccc (Docker Compose configuration file)</pre> <pre>\u251c\u2500\u2500 \ud83d\udcc2 notebooks                                       \u2705 (Project's interactive notebooks)</pre> <pre>\u2502    \u251c\u2500\u2500 crisp_dm_stages.ipynb                         \ud83d\udccc (Notebook for CRISP-DM methodology)</pre> <pre>\u251c\u2500\u2500 \ud83d\udcc2 src                                             \u2705 (Main Python modules of the project)</pre> <pre>\u2502    \u251c\u2500\u2500 __init__.py </pre> <pre>\u2502    \u251c\u2500\u2500 data_pipeline.py                              \ud83d\udccc (Preprocessing pipeline)</pre> <pre>\u2502    \u251c\u2500\u2500 mlflow_logger.py                              \ud83d\udccc (MLflow logging module)</pre> <pre>\u2502    \u251c\u2500\u2500 model_registry.py                             \ud83d\udccc (Model registry management)</pre> <pre>\u2502    \u251c\u2500\u2500 model_trainer.py                              \ud83d\udccc (Model training functions)</pre> <pre>\u2502    \u251c\u2500\u2500 trainer_factory.py                            \ud83d\udccc (Factory for selecting training algorithms)</pre> <pre>\u2502    \u251c\u2500\u2500 water_scan_main.py                            \ud83d\udccc (Main execution script)</pre> <pre>\u251c\u2500\u2500 \ud83d\udcc2 tests                                           \u2705 (Test folder)</pre> <pre>\u2502    \u251c\u2500\u2500 __init__.py </pre> <pre>\u2502    \u251c\u2500\u2500 conftest.py                                   \ud83d\udccc Reusable fixtures (e.g., mock data)</pre> <pre>\u2502    \u251c\u2500\u2500 test_data_pipeline.py                         \ud83d\udccc Tests for data pipeline</pre> <pre>\u2502    \u251c\u2500\u2500 test_model_trainer.py                         \ud83d\udccc Tests for training with RandomForest + Optuna</pre> <pre>\u2502    \u251c\u2500\u2500 test_trainer_factory.py                       \ud83d\udccc Tests for trainer factory</pre> <pre>\u251c\u2500\u2500 .gitignore                                         \ud83d\udccc (Files and folders ignored by Git)</pre> <pre>\u251c\u2500\u2500 .pre-commit-config.yaml                            \u2705 (Pre-commit hooks configuration)</pre> <pre>\u251c\u2500\u2500 .pytest.ini                                        \u2705 (Pytest configuration)</pre> <pre>\u251c\u2500\u2500 .python-version                                    \ud83d\udccc (Python version used)</pre> <pre>\u251c\u2500\u2500 bumpversion.cfg                                    \u2705 (bump2version configuration)</pre> <pre>\u251c\u2500\u2500 Makefile                                           \u2705 (Automation commands for the project)</pre> <pre>\u251c\u2500\u2500 mkdocs.yml                                         \u2705 (MkDocs configuration file)</pre> <pre>\u251c\u2500\u2500 pyproject.toml                                     \u2705 (Project dependency and build management)</pre> <pre>\u251c\u2500\u2500 README.md                                          \ud83d\udccc (Project overview and main instructions)</pre> <p>\u2b05 Back to Home Page</p>"},{"location":"tests/","title":"Automated Testing with Pytest","text":"<p>This project uses the Pytest library to perform automated tests, ensuring code quality, reliability, and maintainability.</p>"},{"location":"tests/#test-structure","title":"\ud83d\udd39 Test Structure","text":"<p>The tests are organized in the <code>tests/</code> directory, separated by component:</p> <pre>\ud83d\udcc2 WATER_SCAN_AI                           \u2705 (Project root directory)</pre> <pre>\u251c\u2500\u2500 \ud83d\udcc2 tests                               \u2705 (Test folder)</pre> <pre>\u2502    \u251c\u2500\u2500 conftest.py                       \ud83d\udccc Reusable fixtures (e.g., mock data)</pre> <pre>\u2502    \u251c\u2500\u2500 test_data_pipeline.py             \ud83d\udccc Tests for the data pipeline</pre> <pre>\u2502    \u251c\u2500\u2500 test_model_trainer.py             \ud83d\udccc Tests for training with RandomForest + Optuna</pre> <pre>\u2502    \u251c\u2500\u2500 test_trainer_factory.py           \ud83d\udccc Tests for the trainer factory</pre>"},{"location":"tests/#tools-used","title":"\ud83d\udd39 Tools Used","text":"<ul> <li><code>pytest</code>: main testing framework</li> <li><code>pytest-cov</code>: code coverage analysis</li> <li><code>monkeypatch</code>: mocking of external functions and methods</li> <li><code>tmp_path fixture</code>: creation of temporary test files</li> </ul>"},{"location":"tests/#fixtures-conftestpy","title":"\ud83d\udd39 Fixtures (conftest.py)","text":"<p>The <code>conftest.py</code> file defines reusable data and configuration for multiple tests.</p>"},{"location":"tests/#tests-created","title":"\ud83d\udd39 Tests Created","text":"<p>\u2705 1) <code>test_data_pipeline.py</code> </p> <ul> <li> <p><code>test_pipeline_load_and_clean</code>  \ud83e\uddea Tests reading a CSV and handling missing values.  \ud83d\udcdd Note: Simulates a <code>.csv</code> file with missing values and checks whether the <code>fillna(median)</code> method in <code>DataPipeline</code> correctly removes NaNs. Ensures the pipeline starts with clean data \u2014 essential to avoid model errors.</p> </li> <li> <p><code>test_data_preprocessing_split_and_smote</code>  \ud83e\uddea Verifies train/test split and SMOTE application.  \ud83d\udcdd Note: Checks that the data is split with stratification (maintaining the <code>Potability</code> proportion) and that SMOTE correctly balances the classes. This guarantees balanced training and prevents bias toward the majority class.</p> </li> </ul> <p>\u2705 2) <code>test_trainer_factory.py</code> </p> <ul> <li> <p><code>test_create_trainer_success</code>  \ud83e\uddea Tests successful creation of a RandomForest trainer.  \ud83d\udcdd Note: Verifies that the factory returns the correct instance (<code>RandomForestTrainer</code>) when receiving <code>random_forest</code> as the input. A key test for validating the modularity of the system through the Factory pattern.</p> </li> <li> <p><code>test_create_trainer_invalid_model</code>  \u26a0\ufe0f Tests error handling when providing an invalid model.  \ud83d\udcdd Note: Ensures the system raises a <code>ValueError</code> when an unsupported model type is passed. Important for protecting the API from misuse and anticipating production failures.</p> </li> </ul> <p>\u2705 3) <code>test_model_trainer.py</code> </p> <ul> <li><code>test_optuna_fake</code>  \ud83e\uddea Tests Optuna optimization execution using monkeypatch, without running a real session.  \ud83d\udcdd Note: Uses <code>monkeypatch</code> to replace the <code>objective()</code> method and force a fixed return (e.g., <code>0.9</code>). This enables testing the Optuna optimization flow without running the actual training or MLflow logging. Ideal for reducing execution time and safely simulating real environments.</li> </ul>"},{"location":"tests/#running-the-tests","title":"\ud83d\udd39 Running the Tests","text":"<p>You can run the tests with:</p> <pre><code>make test\n</code></pre> <p>Or directly using Poetry:</p> <p><code>poetry run pytest --cov=src --cov-report=term-missing</code></p>"},{"location":"tests/#code-coverage","title":"\ud83d\udd39 Code Coverage","text":"<p>Test coverage is automatically generated via <code>pytest-cov</code>. To view it:</p> <p><code>poetry run pytest --cov=src --cov-report=term-missing</code></p> <p>\ud83d\udca1 Use --cov-fail-under=27 to require a minimum of 27% coverage.</p>"},{"location":"tests/#configuracao-do-pytest","title":"\ud83d\udd39 Configura\u00e7\u00e3o do Pytest","text":"<p>The project uses the <code>.pytest.ini</code> file to configure the correct path.</p> <p>\ud83d\udccc Notes (Best practices followed):  \u2705 Modular test structure  \u2705 Use of fixtures to avoid repetition  \u2705 Component mocking with <code>monkeypatch</code>  \u2705 Independent and isolated tests  \u2705 Code coverage with <code>pytest-cov</code> </p>"},{"location":"usage/","title":"Project Usage","text":"<p>This project includes automations via Makefile to simplify the execution of the main tasks. Below are the commands to run the classifier, check code quality, run tests, and update the documentation.</p>"},{"location":"usage/#setting-up-the-environment-with-poetry","title":"\ud83d\udd39 Setting up the environment with Poetry","text":"<p>Before running any command in this project, it is highly recommended to properly configure the Poetry virtual environment. This ensures that all dependencies are correctly installed and managed within the project.</p>"},{"location":"usage/#create-the-virtual-environment-inside-the-project","title":"\ud83d\udd39 Create the virtual environment inside the project","text":"<p>By default, Poetry creates the virtual environment outside the project directory. To keep the virtual environment within the repository, run:</p> <p><code>poetry config virtualenvs.in-project true</code></p> <p>\ud83d\udccc Notes:  \u27a1 This ensures that the virtual environment is created inside the <code>.venv/</code> folder, making management easier.  \u27a1 Useful for maintaining isolated environments for each project.  \u27a1 Avoids conflicts between different dependency versions.</p>"},{"location":"usage/#activate-the-virtual-environment","title":"\ud83d\udd39 Activate the virtual environment","text":"<p>To activate the virtual environment and enter the Poetry shell, run:</p> <p><code>poetry shell</code></p>"},{"location":"usage/#running-the-water-scan-ai-classifier","title":"\ud83d\udd39 Running the Water Scan AI Classifier","text":"<p>To run the Water Scan AI classifier, execute:</p> <p><code>make run</code></p> <p>or directly via Poetry:</p> <p><code>poetry install</code></p> <p><code>poetry run python src/water_scan_main.py</code></p> <p>\ud83d\udccc Notes:  \u27a1 This command handles data loading, preprocessing, training, MLflow logging, and model registration.  \u27a1 It ensures that all dependencies are installed before execution.</p>"},{"location":"usage/#checking-code-quality","title":"\ud83d\udd39 Checking Code Quality","text":"<p>To run code quality checks using pre-commit, execute:</p> <p><code>make quality</code></p> <p>This command runs:</p> <ul> <li>Black (automatic code formatting)</li> <li>Isort (import sorting)</li> <li>Flake8 (code linting)</li> <li>Ruff (optimized linter)</li> <li>Pre-commit hooks to prevent broken commits</li> </ul> <p>If you prefer to run it manually:</p> <p><code>poetry run pre-commit run --all-files</code></p> <p>\ud83d\udccc Notes:  \u27a1 Running <code>make quality</code> before committing helps prevent formatting issues and poor code quality.  \u27a1 Helps maintain a consistent code standard across the project.  \u27a1 Avoids CI/CD pipeline failures by catching errors early.</p>"},{"location":"usage/#running-mkdocs-documentation","title":"\ud83d\udd39 Running MkDocs Documentation","text":"<p>To preview the documentation locally:</p> <p><code>make doc</code></p> <p>or directly via Poetry:</p> <p><code>poetry run mkdocs serve</code></p> <p>Now, open <code>http://127.0.0.1:8000/</code> in your browser.</p> <p>\ud83d\udccc Notes:  \u27a1 Useful for previewing the documentation before publishing.  \u27a1 Keeps the documentation always accessible to the team.  \u27a1 Prevents formatting issues and broken links before deployment. </p>"},{"location":"usage/#publishing-the-documentation-online-github-pages","title":"\ud83d\udd39 Publishing the Documentation Online (GitHub Pages)","text":"<p>After making changes to the documentation, you can publish it online to GitHub Pages using the following command:</p> <p><code>poetry run mkdocs gh-deploy</code></p> <p>This will perform the following:  1\ufe0f\u20e3 Builds the documentation and converts the Markdown (.md) files to HTML.  2\ufe0f\u20e3 Creates a new commit on the <code>gh-pages</code> branch with the latest version of the documentation.  3\ufe0f\u20e3 Updates the public project page available on GitHub Pages. </p> <p>If the project is properly configured, the documentation will be available at:</p> <p><code>https://tralencar.github.io/water_scan_ai/</code></p>"},{"location":"usage/#updating-the-project-version-bump2version","title":"\ud83d\udd39 Updating the Project Version (bump2version)","text":"<p>If you want to bump the project version, use:</p> <pre><code>poetry run bump2version patch   # For small changes\npoetry run bump2version minor   # For minor updates\npoetry run bump2version major   # For major updates\n</code></pre> <p>This will automatically update the project version in <code>pyproject.toml</code>.</p> <p>\ud83d\udccc Notes:  \u27a1 Used to maintain version control as the project evolves.  \u27a1 Important for teams that follow semantic versioning (semver).  \u27a1 Ensures traceability of code changes.</p>"},{"location":"usage/#running-tests-pytest","title":"\ud83d\udd39 Running Tests (pytest)","text":"<p>To run unit tests and check code coverage, execute:</p> <p><code>make test</code></p> <p>This command:</p> <ul> <li>Installs development dependencies</li> <li>Runs <code>pytest</code> with a minimum required coverage of 27%</li> <li>Displays a coverage report</li> </ul> <p>\ud83d\udccc Notes:  \u27a1 Prevents broken code from reaching production.  \u27a1 Ensures correct functionality before adding new features.  \u27a1 The minimum coverage of 8% can be adjusted as more tests are added. This change must be made in the <code>Makefile</code>.</p>"},{"location":"usage/#running-poetry-lock","title":"\ud83d\udd39 Running Poetry Lock","text":"<p>If you need to update the <code>poetry.lock</code> file, execute:</p> <p><code>make lock</code></p> <p>or directly via Poetry:</p> <p><code>poetry lock</code></p> <p>\ud83d\udccc Notes:  \u27a1 Useful when adding or updating packages in <code>pyproject.toml</code>.  \u27a1 Ensures that all dependencies are properly locked.  \u27a1 Prevents conflicts when working in teams.</p>"},{"location":"usage/#managing-mlflow-with-docker-compose","title":"\ud83d\udd39 Managing MLflow with Docker Compose","text":"<p>This project uses Docker Compose to run MLflow Tracking and MinIO services in an automated way. </p>"},{"location":"usage/#building-the-containers","title":"\ud83d\udd27 Building the containers:","text":"<p><code>make build</code></p> <p>\ud83d\udccc Note:  \u27a1 Builds and starts the services defined in <code>mlflow-minio-setup/docker-compose.yml</code> in the background.</p>"},{"location":"usage/#stopping-the-services","title":"\u26d4 Stopping the services:","text":"<p><code>make end</code></p> <p>\ud83d\udccc Note:  \u27a1 Stops the running containers, such as MLflow and MinIO.</p>"},{"location":"usage/#cleaning-up-all-docker-containers","title":"\ud83e\uddf9 Cleaning Up All Docker Containers:","text":"<p><code>make clear_all</code></p> <p>\ud83d\udccc Notes:  \u27a1 Forcefully removes all stopped or running containers.  \u27a1 \u26a0 Use with caution, as it removes all local containers, including those from other projects. </p> <p>\u2b05 Back to Home Page</p>"}]}